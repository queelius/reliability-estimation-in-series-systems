<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Reliability Estimation in Series Systems: Maximum Likelihood Techniques for Right-Censored and Masked Failure Data</title>
  <meta name="description" content="Reliability Estimation in Series Systems: Maximum Likelihood Techniques for Right-Censored and Masked Failure Data" />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Reliability Estimation in Series Systems: Maximum Likelihood Techniques for Right-Censored and Masked Failure Data" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Reliability Estimation in Series Systems: Maximum Likelihood Techniques for Right-Censored and Masked Failure Data" />
  
  
  

<meta name="author" content="Alex Towell" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path=""><a href="#introduction"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path=""><a href="#statmod"><i class="fa fa-check"></i><b>2</b> Series System Model</a>
<ul>
<li class="chapter" data-level="2.1" data-path=""><a href="#comp-cause"><i class="fa fa-check"></i><b>2.1</b> Component Cause of Failure</a></li>
<li class="chapter" data-level="2.2" data-path=""><a href="#reliability"><i class="fa fa-check"></i><b>2.2</b> System and Component Reliabilities</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path=""><a href="#like-model"><i class="fa fa-check"></i><b>3</b> Likelihood Model for Masked Data</a>
<ul>
<li class="chapter" data-level="3.1" data-path=""><a href="#candmod"><i class="fa fa-check"></i><b>3.1</b> Masked Component Cause of Failure</a></li>
<li class="chapter" data-level="3.2" data-path=""><a href="#right-censored-data"><i class="fa fa-check"></i><b>3.2</b> Right-Censored Data</a></li>
<li class="chapter" data-level="3.3" data-path=""><a href="#identifiability-and-convergence-issues"><i class="fa fa-check"></i><b>3.3</b> Identifiability and Convergence Issues</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path=""><a href="#mle"><i class="fa fa-check"></i><b>4</b> Maximum Likelihood Estimation</a></li>
<li class="chapter" data-level="5" data-path=""><a href="#boot"><i class="fa fa-check"></i><b>5</b> Bias-Corrected and Accelerated Bootstrap Confidence Intervals</a></li>
<li class="chapter" data-level="6" data-path=""><a href="#weibull"><i class="fa fa-check"></i><b>6</b> Series System with Weibull Components</a>
<ul>
<li class="chapter" data-level="6.1" data-path=""><a href="#reliability-1"><i class="fa fa-check"></i><b>6.1</b> Reliability</a></li>
<li class="chapter" data-level="6.2" data-path=""><a href="#sys-weibull-like"><i class="fa fa-check"></i><b>6.2</b> Likelihood Model</a></li>
<li class="chapter" data-level="6.3" data-path=""><a href="#reduced-weibull"><i class="fa fa-check"></i><b>6.3</b> Weibull Series System: Homogeneous Shape Parameters</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path=""><a href="#sim-study"><i class="fa fa-check"></i><b>7</b> Simulation Study: Series System with Weibull Components</a>
<ul>
<li class="chapter" data-level="7.1" data-path=""><a href="#data-gen-proc"><i class="fa fa-check"></i><b>7.1</b> Data Generating Process</a>
<ul>
<li class="chapter" data-level="" data-path=""><a href="#series-system-lifetime"><i class="fa fa-check"></i>Series System Lifetime</a></li>
<li class="chapter" data-level="" data-path=""><a href="#right-censoring-model"><i class="fa fa-check"></i>Right-Censoring Model</a></li>
<li class="chapter" data-level="" data-path=""><a href="#masking-model-for-component-cause-of-failure"><i class="fa fa-check"></i>Masking Model for Component Cause of Failure</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path=""><a href="#simulation-scenarios"><i class="fa fa-check"></i><b>7.2</b> Simulation Scenarios</a></li>
<li class="chapter" data-level="7.3" data-path=""><a href="#effect-censoring"><i class="fa fa-check"></i><b>7.3</b> Scenario: Assessing the Impact of Right-Censoring</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path=""><a href="#key-observations"><i class="fa fa-check"></i><b>7.3.1</b> Key Observations</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path=""><a href="#effect-samp-size"><i class="fa fa-check"></i><b>7.4</b> Scenario: Assessing the Impact of Sample Size</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path=""><a href="#key-observations-1"><i class="fa fa-check"></i><b>7.4.1</b> Key Observations</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path=""><a href="#p-vs-mttf"><i class="fa fa-check"></i><b>7.5</b> Scenario: Assessing the Impact of Masking Probability for Component Cause of Failure</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path=""><a href="#key-observations-2"><i class="fa fa-check"></i><b>7.5.1</b> Key Observations</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path=""><a href="#scale-vs-mttf"><i class="fa fa-check"></i><b>7.6</b> Scenario: Assessing the Impact of Changing the Scale Parameter of Component 3</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path=""><a href="#key-observations-3"><i class="fa fa-check"></i><b>7.6.1</b> Key Observations</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path=""><a href="#shape3-vary"><i class="fa fa-check"></i><b>7.7</b> Scenario: Assessing the Impact of Changing the Shape Parameter of Component 3</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path=""><a href="#key-observations-4"><i class="fa fa-check"></i><b>7.7.1</b> Key Observations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path=""><a href="#future-work"><i class="fa fa-check"></i><b>8</b> Future Work</a></li>
<li class="chapter" data-level="9" data-path=""><a href="#conclusion"><i class="fa fa-check"></i><b>9</b> Conclusion</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path=""><a href="#app-weibull-loglik-r"><i class="fa fa-check"></i><b>A</b> Log-likelihood Function</a></li>
<li class="chapter" data-level="B" data-path=""><a href="#app-score-fn-r"><i class="fa fa-check"></i><b>B</b> Score Function</a></li>
<li class="chapter" data-level="C" data-path=""><a href="#app-sim-study-r"><i class="fa fa-check"></i><b>C</b> Scenario Simulation</a></li>
<li class="chapter" data-level="D" data-path=""><a href="#app-cand-model-r"><i class="fa fa-check"></i><b>D</b> Bernoulli Candidate Set Model</a></li>
<li class="chapter" data-level="E" data-path=""><a href="#app-series-quantile"><i class="fa fa-check"></i><b>E</b> Series System Quantile Function</a>
<ul>
<li class="chapter" data-level="E.1" data-path=""><a href="#introduction-1"><i class="fa fa-check"></i><b>E.1</b> Introduction</a></li>
<li class="chapter" data-level="E.2" data-path=""><a href="#series-system-model"><i class="fa fa-check"></i><b>E.2</b> Series System Model</a></li>
<li class="chapter" data-level="E.3" data-path=""><a href="#likelihood-model"><i class="fa fa-check"></i><b>E.3</b> Likelihood Model</a></li>
<li class="chapter" data-level="E.4" data-path=""><a href="#estimation-methodology"><i class="fa fa-check"></i><b>E.4</b> Estimation Methodology</a></li>
<li class="chapter" data-level="E.5" data-path=""><a href="#simulation-studies"><i class="fa fa-check"></i><b>E.5</b> Simulation Studies</a></li>
<li class="chapter" data-level="E.6" data-path=""><a href="#conclusion-1"><i class="fa fa-check"></i><b>E.6</b> Conclusion</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Reliability Estimation in Series Systems: Maximum Likelihood Techniques for Right-Censored and Masked Failure Data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Reliability Estimation in Series Systems: Maximum Likelihood Techniques for Right-Censored and Masked Failure Data</h1>
<p class="author"><em>Alex Towell</em></p>
<div class="abstract">
<p class="abstract">Abstract</p>
Accurately estimating reliability of individual components in multi-component systems is challenging when only system-level failure data is observable. This paper develops maximum likelihood techniques to estimate component reliability from right-censored lifetimes and candidate sets indicative of masked failure causes in series systems. A likelihood model accounts for right-censoring and candidate sets. Extensive simulation studies demonstrate accurate and robust performance of the maximum likelihood estimator despite small samples and significant masking and censoring. The bias-corrected accelerated bootstrap provides well-calibrated confidence intervals. The methods expand the capability to quantify latent component properties from limited system reliability data. Key contributions include derivations of likelihood models and validation of estimation techniques via simulations. Together, these advance rigorous component reliability assessment from masked failure data.
</div>
</div>
<div id="introduction" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">1</span> Introduction<a href="#introduction" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Accurately estimating the reliability of individual components in multi-component
systems is an important challenge, as component lifetimes and failure causes are
often not directly observable. In a series system <span class="citation">(Agustin <a href="#ref-Agustin-2011" role="doc-biblioref">2011</a>)</span>, only
system-level failure times may be recorded along with limited information about
the failed component. Such masked data poses difficulties for assessing component
reliability.</p>
<p>This paper develops and validates maximum likelihood techniques to estimate
component reliability from right-censored lifetime data and candidate sets
indicative of component failure causes. The key results are:</p>
<ul>
<li><p>Deriving a likelihood model incorporating right-censoring and candidate sets
to enable masked data to be used for parameter estimation.</p></li>
<li><p>Demonstrating through simulation studies that the maximum likelihood estimator
performs well despite small samples and significant masking and
right-censoring.</p></li>
<li><p>Estimation of scale parameters is more robust than shape parameters in the
Weibull model.</p></li>
<li><p>Showing that bootstrapping provides reasonably well-calibrated confidence
intervals for the maximum likelihood estimates, even with small sample sizes.</p></li>
</ul>
<p>The remainder of the paper details the series system and likelihood models,
maximum likelihood estimation methodology, bootstrap confidence interval
estimation, and extensive simulation studies exploring estimator behavior under
various sample sizes, masking levels, and model assumptions. Together, these
contributions provide a statistically rigorous framework for learning about
latent component properties from limited observational data on system
reliability. The proposed methods expand the capability to quantify component
lifetimes in situations where failure data is significantly masked.</p>
</div>
<div id="statmod" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">2</span> Series System Model<a href="#statmod" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Consider a system composed of <span class="math inline">\(m\)</span> components arranged in a series configuration.
Each component and system has two possible states, functioning or failed.
We have <span class="math inline">\(n\)</span> systems whose lifetimes are independent and identically distributed (i.i.d.).
The lifetime of the <span class="math inline">\(i\)</span> system is denoted by the random variable <span class="math inline">\(T_{i}\)</span>
and the lifetime of its <span class="math inline">\(j\)</span> component is denoted by the random variable <span class="math inline">\(T_{i j}\)</span>.
We assume the component lifetimes in a single system are statistically independent and non-identically distributed.
Here, lifetime (or lifespan) is defined as the elapsed time from when the new, functioning component
(or system) is put into operation until it fails for the first time.
A series system fails when any component fails, thus the lifetime of the <span class="math inline">\(i\)</span>
system is given by the component with the shortest lifetime,
<span class="math display">\[
    T_i = \min\bigr\{T_{i 1},T_{i 2}, \ldots, T_{i m} \bigr\}.
\]</span></p>
<p>There are three particularly important distribution functions in reliability analysis: the
reliability function, the probability density function, and the hazard function.
The reliability function, <span class="math inline">\(R_{T_i}(t)\)</span>, is the
probability that the <span class="math inline">\(i\)</span> system has a lifetime greater than
given duration <span class="math inline">\(t\)</span>,
<span class="math display">\[\begin{equation}
R_{T_i}(t) = \Pr\{T_i &gt; t\}\\
\end{equation}\]</span>
The probability density function (pdf) of <span class="math inline">\(T_i\)</span> is denoted by
<span class="math inline">\(f_{T_i}(t)\)</span> and may be defined as
<span class="math display">\[
    f_{T_i}(t) = -\frac{d}{dt} R_{T_i}(t).
\]</span>
Next, we introduce the hazard function.
The probability that a failure occurs between <span class="math inline">\(t\)</span> and <span class="math inline">\(\Delta t\)</span> given that no
failure occurs before time <span class="math inline">\(t\)</span> is given by
<span class="math display">\[
\Pr\{T_i \leq t+\Delta t|T_i &gt; t\} = \frac{\Pr\{t &lt; T_i &lt; t+\Delta t\}}{\Pr\{T_i &gt; t\}}.
\]</span>
The failure rate is given by the dividing this equation by the length of the time
interval, <span class="math inline">\(\Delta t\)</span>:
<span class="math display">\[
\frac{\Pr\{t &lt; T_i &lt; t+\Delta t\}}{\Delta t} \frac{1}{\Pr\{T_i &gt; t\}} =
    -\frac{R_{T_i}(t+\Delta t) - R_{T_i}(t)}{\Delta t} \frac{1}{R_{T_i}(t)}.
\]</span>
The hazard function <span class="math inline">\(h_{T_i}(t)\)</span> for <span class="math inline">\(T_i\)</span> is the instantaneous failure rate at time <span class="math inline">\(t\)</span>,
which is given by
<span class="math display">\[\begin{equation}
\label{eq:failure_rate}
\begin{split}
h_{T_i}(t) 
  &amp;= -\lim_{\Delta t \to 0} \frac{R_{T_i}(t+\Delta t) - R_{T_i}(t)}{\Delta t}
    \frac{1}{R_{T_i}(t)}\\
  &amp;= \left(-\frac{d}{dt} R_{T_i}(t)\right) \frac{1}{R_{T_i}(t)} = \frac{f_{T_i}(t)}{R_{T_i}(t)}.
\end{split}
\end{equation}\]</span></p>
<p>The lifetime of the <span class="math inline">\(j\)</span> component is assumed to follow a parametric distribution indexed
by a parameter vector <span class="math inline">\(\boldsymbol{\theta_j}\)</span>. The parameter vector of the overall system is defined as
<span class="math display">\[
    \boldsymbol{\theta }= (\boldsymbol{\theta_1},\ldots,\boldsymbol{\theta_m}).
\]</span></p>
<p>When a random variable <span class="math inline">\(X\)</span> is parameterized by a particular <span class="math inline">\(\boldsymbol{\theta}\)</span>, we denote the
reliability function by <span class="math inline">\(R_X(t;\boldsymbol{\theta})\)</span>, and the same for the other distribution functions.
As a special case, for the components in a series system, we subscript by their labels, e.g,
the pdf of the <span class="math inline">\(j\)</span> component is denoted by <span class="math inline">\(f_j(t;\boldsymbol{\theta_j})\)</span>. Two continuous
random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> have a joint pdf <span class="math inline">\(f_{X,Y}(x,y)\)</span>.
Given the joint pdf <span class="math inline">\(f(x,y)\)</span>, the marginal pdf of <span class="math inline">\(X\)</span> is given by
<span class="math display">\[
f_X(x) = \int_{\mathcal{Y}} f_{X,Y}(x,y) dy,
\]</span>
where <span class="math inline">\(\mathcal{Y}\)</span> is the support of <span class="math inline">\(Y\)</span>. (If <span class="math inline">\(Y\)</span> is discrete, replace
the integration with a summation over <span class="math inline">\(\mathcal{Y}\)</span>.)</p>
<p>The conditional pdf of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X=x\)</span>, <span class="math inline">\(f_{Y|X}(y|x)\)</span>, is defined as
<span class="math display">\[
f_{X|Y}(y|x) = \frac{f_{X,Y}(x,y)}{f_X(x)}.
\]</span>
We may generalize all of the above to more than two random variables, e.g.,
the joint pdf of <span class="math inline">\(X_1,\ldots,X_m\)</span> is denoted by <span class="math inline">\(f(x_1,\ldots,x_m)\)</span>.</p>
<p>Next, we dive deeper into these concepts and provide mathematical derivations for
the reliability function, pdf, and hazard function of the series system.
We begin with the reliability function of the series system, as given by the following theorem.</p>
<div class="theorem">
<p><span id="thm:sys-reliability-function" class="theorem"><strong>Theorem 2.1  </strong></span>The series system has a reliability function given by
<span class="math display">\[\begin{equation}
\label{eq:sys_reliability_function}
R_{T_i}(t;\boldsymbol{\theta}) = \prod_{j=1}^m R_j(t;\boldsymbol{\theta_j}).
\end{equation}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-1" class="proof"><em>Proof</em>. </span>The reliability function is defined as
<span class="math display">\[
  R_{T_i}(t;\boldsymbol{\theta}) = \Pr\{T_i &gt; t\}
\]</span>
which may be rewritten as
<span class="math display">\[
  R_{T_i}(t;\boldsymbol{\theta}) = \Pr\{\min\{T_{i 1},\ldots,T_{i m}\} &gt; t\}.
\]</span>
For the minimum to be larger than <span class="math inline">\(t\)</span>, every component must be larger than <span class="math inline">\(t\)</span>,
<span class="math display">\[
  R_{T_i}(t;\boldsymbol{\theta}) = \Pr\{T_{i 1} &gt; t,\ldots,T_{i m} &gt; t\}.
\]</span>
Since the component lifetimes are independent, by the product rule the above may
be rewritten as
<span class="math display">\[
  R_{T_i}(t;\boldsymbol{\theta}) = \Pr\{T_{i 1} &gt; t\} \times \cdots \times \Pr\{T_{i m} &gt; t\}.
\]</span>
By definition, <span class="math inline">\(R_j(t;\boldsymbol{\theta}) = \Pr\{T_{i j} &gt; t\}\)</span>.
Performing this substitution obtains the result
<span class="math display">\[
  R_{T_i}(t;\boldsymbol{\theta}) = \prod_{j=1}^m R_j(t;\boldsymbol{\theta_j}).
\]</span></p>
</div>
<p>Theorem <a href="#thm:sys-reliability-function">2.1</a> shows that the system’s overall reliability is the
product of the reliabilities of its individual components. This is an important relationship
in all series systems and will be used in the subsequent derivations. Next, we turn our
attention to the pdf of the system lifetime, described in the following theorem.</p>
<div class="theorem">
<p><span id="thm:sys-pdf" class="theorem"><strong>Theorem 2.2  </strong></span>The series system has a pdf given by
<span class="math display">\[\begin{equation}
\label{eq:sys_pdf}
f_{T_i}(t;\boldsymbol{\theta}) = \sum_{j=1}^m f_j(t;\boldsymbol{\theta_j})
    \prod_{\substack{k=1\\k\neq j}}^m R_k(t;\boldsymbol{\theta_j}).
\end{equation}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-2" class="proof"><em>Proof</em>. </span>By definition, the pdf may be written as
<span class="math display">\[
    f_{T_i}(t;\boldsymbol{\theta}) = -\frac{d}{dt} \prod_{j=1}^m R_j(t;\boldsymbol{\theta_j}).
\]</span>
By the product rule, this may be rewritten as
<span class="math display">\[\begin{align*}
  f_{T_i}(t;\boldsymbol{\theta})
    &amp;= -\frac{d}{dt} R_1(t;\boldsymbol{\theta_1})\prod_{j=2}^m R_j(t;\boldsymbol{\theta_j}) -
      R_1(t;\boldsymbol{\theta_1}) \frac{d}{dt} \prod_{j=2}^m R_j(t;\boldsymbol{\theta_j})\\
    &amp;= f_1(t;\boldsymbol{\theta}) \prod_{j=2}^m R_j(t;\boldsymbol{\theta_j}) -
      R_1(t;\boldsymbol{\theta_1}) \frac{d}{dt} \prod_{j=2}^m R_j(t;\boldsymbol{\theta_j}).
\end{align*}\]</span>
Recursively applying the product rule <span class="math inline">\(m-1\)</span> times results in
<span class="math display">\[
f_{T_i}(t;\boldsymbol{\theta}) = \sum_{j=1}^{m-1} f_j(t;\boldsymbol{\theta_j})
    \prod_{\substack{k=1\\k \neq j}}^m R_k(t;\boldsymbol{\theta_k}) -
    \prod_{j=1}^{m-1} R_j(t;\boldsymbol{\theta_j}) \frac{d}{dt} R_m(t;\boldsymbol{\theta_m}),
\]</span>
which simplifies to
<span class="math display">\[
f_{T_i}(t;\boldsymbol{\theta})= \sum_{j=1}^m f_j(t;\boldsymbol{\theta_j})
    \prod_{\substack{k=1\\k \neq j}}^m R_k(t;\boldsymbol{\theta_k}).
\]</span></p>
</div>
<p>Theorem <a href="#thm:sys-pdf">2.2</a> shows the pdf of the system lifetime is a function of
the pdfs and reliabilities of its components. We continue with the hazard
function of the system lifetime, defined in the next theorem.</p>
<div class="theorem">
<p><span id="thm:sys-failure-rate" class="theorem"><strong>Theorem 2.3  </strong></span>The series system has a hazard function given by
<span class="math display">\[\begin{equation}
\label{eq:sys-failure-rate}
  h_{T_i}(t;\boldsymbol{\theta}) = \sum_{j=1}^m h_j(t;\boldsymbol{\theta_j}).
\end{equation}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-3" class="proof"><em>Proof</em>. </span>By Equation , the <span class="math inline">\(i\)</span> series system lifetime has a hazard function defined as
<span class="math display">\[
  h_{T_i}(t;\boldsymbol{\theta}) = \frac{f_{T_i}(t;\boldsymbol{\theta})}{R_{T_i}(t;\boldsymbol{\theta})}.
\]</span>
Plugging in expressions for these functions results in
<span class="math display">\[
  h_{T_i}(t;\boldsymbol{\theta}) = \frac{\sum_{j=1}^m f_j(t;\boldsymbol{\theta_j})
    \prod_{\substack{k=1\\k \neq j}}^m R_k(t;\boldsymbol{\theta_k})}
      {\prod_{j=1}^m R_j(t;\boldsymbol{\theta_j})},
\]</span>
which can be simplified to
<span class="math display">\[
h_{T_i}(t;\boldsymbol{\theta}) = \sum_{j=1}^m \frac{f_j(t;\boldsymbol{\theta_j})}{R_j(t;\boldsymbol{\theta_j})} = \sum_{j=1}^m h_j(t;\boldsymbol{\theta_j}).
\]</span></p>
</div>
<p>Theorem <a href="#thm:sys-failure-rate">2.3</a> reveals that the system’s hazard function is the sum
of the hazard functions of its components. By definition, the hazard function is the ratio of
the pdf to the reliability function,
<span class="math display">\[
h_{T_i}(t;\boldsymbol{\theta}) = \frac{f_{T_i}(t;\boldsymbol{\theta})}{R_{T_i}(t;\boldsymbol{\theta})},
\]</span>
and we can rearrange this to get
<span class="math display">\[\begin{equation}
\label{eq:sys_pdf_2}
\begin{split}
f_{T_i}(t;\boldsymbol{\theta}) &amp;= h_{T_i}(t;\boldsymbol{\theta}) R_{T_i}(t;\boldsymbol{\theta})\\
              &amp;= \biggl\{\sum_{j=1}^m h_j(t;\boldsymbol{\theta_j})\biggr\}
                 \biggl\{ \prod_{j=1}^m R_j(t;\boldsymbol{\theta_j}) \biggr\},
\end{split}
\end{equation}\]</span>
which we find to be a more convenient form than Equation .</p>
<p>In this section, we derived the mathematical forms for the system’s reliability,
probability density, and hazard functions. Next, we build upon these concepts to
derive distributions related to the component cause of failure.</p>
<div id="comp-cause" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Component Cause of Failure<a href="#comp-cause" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Whenever a series system fails, precisely one of the components is the cause.
We denote the component cause of failure of a series system by the random
variable <span class="math inline">\(K_i\)</span>, whose support is given by <span class="math inline">\(\{1,\ldots,m\}\)</span>.
For example, <span class="math inline">\(K_i=j\)</span> indicates that the component indexed by <span class="math inline">\(j\)</span> failed first, i.e.,
<span class="math display">\[
    T_{i j} &lt; T_{i j&#39;}
\]</span>
for every <span class="math inline">\(j&#39;\)</span> in the support of <span class="math inline">\(K_i\)</span> except for <span class="math inline">\(j\)</span>.
Since we have series systems, <span class="math inline">\(K_i\)</span> is unique.</p>
<p>The system lifetime and the component cause of failure has a joint distribution
given by the following theorem.</p>
<div class="theorem">
<p><span id="thm:f-k-and-t" class="theorem"><strong>Theorem 2.4  </strong></span>The joint pdf of the component cause of failure <span class="math inline">\(K_i\)</span> and series system lifetime
<span class="math inline">\(T_i\)</span> is given by
<span class="math display">\[\begin{equation}
\label{eq:f_k_and_t}
  f_{K_i,T_i}(j,t;\boldsymbol{\theta}) = h_j(t;\boldsymbol{\theta_j}) \prod_{l=1}^m R_l(t;\boldsymbol{\theta}),
\end{equation}\]</span>
where <span class="math inline">\(h_l(t;\boldsymbol{\theta_j})\)</span> and <span class="math inline">\(R_l(t;\boldsymbol{\theta_l})\)</span> are respectively the hazard
and reliability functions of the <span class="math inline">\(l\)</span> component.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-4" class="proof"><em>Proof</em>. </span>Consider a series system with <span class="math inline">\(3\)</span> components.
By the assumption that component lifetimes are mutually independent,
the joint pdf of <span class="math inline">\(T_{i 1},T_{i 2},T_{i 3}\)</span> is given by
<span class="math display">\[
    f(t_1,t_2,t_3;\boldsymbol{\theta}) = \prod_{j=1}^{3} f_j(t_j;\boldsymbol{\theta_j}),
\]</span>
where <span class="math inline">\(f_j(t_j;\boldsymbol{\theta_j})\)</span> is the pdf of the <span class="math inline">\(j\)</span> component.
The first component is the cause of failure at time <span class="math inline">\(t\)</span> if <span class="math inline">\(K_i = 1\)</span> and
<span class="math inline">\(T_i = t\)</span>, which may be rephrased as the likelihood that <span class="math inline">\(T_{i 1} = t\)</span>,
<span class="math inline">\(T_{i 2} &gt; t\)</span>, and <span class="math inline">\(T_{i 3} &gt; t\)</span>. Thus,
<span class="math display">\[\begin{align*}
f_{K_i,T_i}(j,t;\boldsymbol{\theta}) 
    &amp;= \int_t^{\infty} \int_t^{\infty}
        f_1(t;\boldsymbol{\theta_1}) f_2(t_2;\boldsymbol{\theta_2}) f_3(t_3;\boldsymbol{\theta_3})
        dt_3 dt_2\\
     &amp;= \int_t^{\infty} f_1(t;\boldsymbol{\theta_1}) f_2(t_2;\boldsymbol{\theta_2})
        R_3(t;\boldsymbol{\theta_3}) dt_2\\
     &amp;= f_1(t;\boldsymbol{\theta_1}) R_2(t;\boldsymbol{\theta_2}) R_3(t_1;\boldsymbol{\theta_3}).
\end{align*}\]</span>
By definition, <span class="math inline">\(f_1(t;\boldsymbol{\theta_1}) = h_1(t;\boldsymbol{\theta_1}) R_1(t;\boldsymbol{\theta_1})\)</span>,
and when we make this substitution into the above expression for <span class="math inline">\(f_{K_i,T_i}(j,t;\boldsymbol{\theta})\)</span>,
we obtain the result
<span class="math display">\[
f_{K_i,T_i}(j,t;\boldsymbol{\theta}) = h_1(t;\boldsymbol{\theta_1}) \prod_{l=1}^m R_l(t;\boldsymbol{\theta_l}).
\]</span>
Generalizing this result completes the proof.</p>
</div>
<p>Theorem <a href="#thm:f-k-and-t">2.4</a> shows that the joint pdf of the component cause of
failure and system lifetime is a function of the hazard functions and reliability
functions of the components. This result will be used in the Section <a href="#like-model">3</a>
to derive the likelihood function for the masked data.</p>
<p>The probability that the <span class="math inline">\(j\)</span> component is the cause of failure
is given by the following theorem.</p>
<div class="theorem">
<p><span id="thm:prob-k" class="theorem"><strong>Theorem 2.5  </strong></span>The probability that the <span class="math inline">\(j\)</span> component is the cause of failure
is given by
<span class="math display">\[\begin{equation}
\label{eq:prob_k}
\Pr\{K_i = j\} = E_{\boldsymbol{\theta}}
\biggl[
    \frac{h_j(T_i;\boldsymbol{\theta_j})}
         {\sum_{l=1}^m h_l(T_i ; \boldsymbol{\theta_l})}
\biggr]
\end{equation}\]</span>
where <span class="math inline">\(K_i\)</span> is the random variable denoting the component cause of failure of the
<span class="math inline">\(i\)</span> system and <span class="math inline">\(T_i\)</span> is the random variable denoting the
lifetime of the <span class="math inline">\(i\)</span> system.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-5" class="proof"><em>Proof</em>. </span>The probability the <span class="math inline">\(j\)</span> component is the cause of failure is given by
marginalizing the joint pdf of <span class="math inline">\(K_i\)</span> and <span class="math inline">\(T_i\)</span> over <span class="math inline">\(T_i\)</span>,
<span class="math display">\[
\Pr\{K_i = j\} = \int_0^{\infty} f_{K_i,T_i}(j,t;\boldsymbol{\theta}) dt.
\]</span>
By Theorem <a href="#thm:f-k-and-t">2.4</a>, this is equivalent to
<span class="math display">\[\begin{align*}
\Pr\{K_i = j\}
    &amp;= \int_0^{\infty} h_j(t;\boldsymbol{\theta_j}) R_{T_i}(t;\boldsymbol{\theta}) dt\\
    &amp;= \int_0^{\infty} \biggl(\frac{h_j(t;\boldsymbol{\theta_j})}{h_{T_i}(t ; \boldsymbol{\theta})}\biggr) f_{T_i}(t ; \boldsymbol{\theta}) dt\\
    &amp;= E_{\boldsymbol{\theta}}\biggl[\frac{h_j(T_i;\boldsymbol{\theta_j})}{\sum_{l=1}^m h_l(T_i ; \boldsymbol{\theta_l})}\biggr].
\end{align*}\]</span></p>
</div>
<div class="theorem">
<p><span id="thm:prob-k-given-t" class="theorem"><strong>Theorem 2.6  </strong></span>The probability that the <span class="math inline">\(j\)</span>
component is the cause of system failure given that we know the system failure
occured at time <span class="math inline">\(t_i\)</span> is given by
<span class="math display">\[
\Pr\{K_i = j|T_i=t_i\} = \frac{h_j(t_i;\boldsymbol{\theta_j})}{\sum_{l=1}^m h_l(t_i;\boldsymbol{\theta_l})}.
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-6" class="proof"><em>Proof</em>. </span>By the definition of conditional probability,
<span class="math display">\[\begin{align*}
    \Pr\{K_i = j|T_i = t_i\} 
        &amp;= \frac{f_{K_i,T_i}(j, t_i;\boldsymbol{\theta})}{f_{T_i}(t_i;\boldsymbol{\theta})}\\
        &amp;= \frac{h_j(t_i;\boldsymbol{\theta_j}) R_{T_i}(t_i;\boldsymbol{\theta})}{f_{T_i}(t_i;\boldsymbol{\theta})}.
\end{align*}\]</span>
Since <span class="math inline">\(f_{T_i}(t_i;\boldsymbol{\theta}) = h_{T_i}(t_i;\boldsymbol{\theta}) R_{T_i}(t_i;\boldsymbol{\theta})\)</span>,
we make this substitution and simplify to obtain
<span class="math display">\[
\Pr\{K_i = j|T_i = t_i\} = \frac{h_j(t_i;\boldsymbol{\theta_j})}{\sum_{l=1}^m h_l(t_i;\boldsymbol{\theta_l})}.
\]</span></p>
</div>
<p>Theorems <a href="#thm:prob-k">2.5</a> and <a href="#thm:prob-k-given-t">2.6</a> are closely related.
Theorem <a href="#thm:prob-k-given-t">2.6</a> is a special case of Theorem <a href="#thm:prob-k">2.5</a>
when <span class="math inline">\(T_i\)</span> is known to be <span class="math inline">\(t_i\)</span>.</p>
</div>
<div id="reliability" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> System and Component Reliabilities<a href="#reliability" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A common measure of reliability is mean time to failure (MTTF). The
MTTF is defined as the expectation of the lifetime,
<span class="math display">\[\begin{equation}
\label{mttf-sys}
\text{MTTF} = E_{\boldsymbol{\theta}}\{T_i\},
\end{equation}\]</span>
which if certain assumptions are satisfied<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> is equivalent to the integration
of the reliability function over its support.</p>
<p>While the MTTF provides a summary measure of reliability, it is not a complete description.
Depending on the failure characteristics, MTTF can be misleading. For example,
a system that has a high likelihood of failing early in its life may still have a
large MTTF if it is fat-tailed.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>The reliability of the components in the series system determines the reliability
of the system. We denote the MTTF of the <span class="math inline">\(j\)</span> component by
<span class="math inline">\(\text{MTTF}_j\)</span> and, according to Theorem <a href="#thm:prob-k">2.5</a>, the probability
that the <span class="math inline">\(j\)</span> component is the cause of failure is given by
<span class="math inline">\(\Pr\{K_i = j\}\)</span>. In a well-designed series system, there is no component that is
the “weakest link” that either has a much shorter MTTF or a much higher
probability of being the component cause of failure than any of
the other components, e.g., <span class="math inline">\(\Pr\{K_i = j\} \approx \Pr\{K_i = k\}\)</span> and
and MTTF<span class="math inline">\(_j \approx\)</span> MTTF<span class="math inline">\(_k\)</span> for all <span class="math inline">\(j\)</span> and <span class="math inline">\(k\)</span>. This just means that the components
should have similar reliabilities and failure characteristics.</p>
<p>We use these results in the simulation study in Section <a href="#sim-study">7</a>, where we
assess the sensitivity of the MLE with respect to varying the reliability
of one of the Weibull components. We vary its reliability in two different ways:</p>
<ol style="list-style-type: decimal">
<li><p>We vary its shape parameter (keeping its scale parameter constant), which determines
the failure characteristics of the component and also affects its MTTF.</p></li>
<li><p>We vary its scale parameter (keeping its shape parameter constant), which scales
its MTTF while retaining the same failure characteristics.</p></li>
</ol>
</div>
</div>
<div id="like-model" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">3</span> Likelihood Model for Masked Data<a href="#like-model" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>We aim to estimate an unknown parameter, <span class="math inline">\(\boldsymbol{\theta}\)</span>, using <em>masked data</em>,
which can have two types of masking. We consider two types of masking:
censoring of system failures and masking component causes of failure.</p>
<div id="censoring" class="section level5 unnumbered hasAnchor" number="">
<h5>Censoring<a href="#censoring" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>We generally encounter two types of censoring: the system failure is observed
to occur within some time interval, or the system failure is not observed
but we know that it was functioning at least until some point in time. The latter
is known as <em>right-censoring</em>, which is the type of censoring we consider in
this paper.</p>
</div>
<div id="component-cause-of-failure-masking" class="section level5 unnumbered hasAnchor" number="">
<h5>Component Cause of Failure Masking<a href="#component-cause-of-failure-masking" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>In the case of masking the component cause of failure, we may not know the
precise component cause of failure, but we may have some indication. A common
example is when a diagnostician is able to isolate the cause of failure to a
subset of the components. We call this subset the <em>candidate set</em>.</p>
</div>
<div id="masked-data" class="section level5 unnumbered hasAnchor" number="">
<h5>Masked Data<a href="#masked-data" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>In this paper, each system is put into operation and observed until either it
fails or its failure is right-censored after some duration <span class="math inline">\(\tau\)</span>, so we do not
directly observe the system lifetime but rather we observe the right-censored
lifetime, <span class="math inline">\(S_i\)</span>, which is given by
<span class="math display">\[\begin{equation}
    S_i = \min\{\tau, T_i\}.
\end{equation}\]</span>
We also observe an event indicator, <span class="math inline">\(\delta_i\)</span>, which is given by
<span class="math display">\[\begin{equation}
    \delta_i = 1_{T_i &lt; \tau},
\end{equation}\]</span>
where <span class="math inline">\(1_{\text{condition}}\)</span> is an indicator function that denotes <span class="math inline">\(1\)</span> if
the condition is true and <span class="math inline">\(0\)</span> otherwise.
Here, <span class="math inline">\(\delta_i = 1\)</span> indicates the <span class="math inline">\(i\)</span> system’s failure was
observed and <span class="math inline">\(\delta_i = 0\)</span> indicates it was right-censored.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>
If a system failure event is observed (<span class="math inline">\(\delta_i = 1\)</span>), then we also observe a
candidate set that contains the component cause of failure. We denote the
candidate set for the <span class="math inline">\(i\)</span> system by <span class="math inline">\(\mathcal{C}_i\)</span>, which
is a subset of <span class="math inline">\(\{1,\ldots,m\}\)</span>.</p>
In summary, the observed data is assumed to be i.i.d. and is given by
<span class="math inline">\(D = \{D_1, \ldots, D_n\}\)</span>, where each <span class="math inline">\(D_i\)</span> contains the following elements:
<p>The masked data generation process is illustrated in Figure .</p>
<p>An example of masked data <span class="math inline">\(D\)</span> with a right-censoring time <span class="math inline">\(\tau = 5\)</span> can be seen in Table 1
for a series system with <span class="math inline">\(3\)</span> components.</p>
<table>
<caption>Right-censored lifetime data with masked component cause of failure.</caption>
<colgroup>
<col width="7%" />
<col width="36%" />
<col width="31%" />
<col width="24%" />
</colgroup>
<thead>
<tr class="header">
<th>System</th>
<th>Right-censored lifetime (<span class="math inline">\(S_i\)</span>)</th>
<th>Event indicator (<span class="math inline">\(\delta_i\)</span>)</th>
<th>Candidate set (<span class="math inline">\(\mathcal{C}_i\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><span class="math inline">\(1.1\)</span></td>
<td>1</td>
<td><span class="math inline">\(\{1,2\}\)</span></td>
</tr>
<tr class="even">
<td>2</td>
<td><span class="math inline">\(1.3\)</span></td>
<td>1</td>
<td><span class="math inline">\(\{2\}\)</span></td>
</tr>
<tr class="odd">
<td>4</td>
<td><span class="math inline">\(2.6\)</span></td>
<td>1</td>
<td><span class="math inline">\(\{2,3\}\)</span></td>
</tr>
<tr class="even">
<td>5</td>
<td><span class="math inline">\(3.7\)</span></td>
<td>1</td>
<td><span class="math inline">\(\{1,2,3\}\)</span></td>
</tr>
<tr class="odd">
<td>6</td>
<td><span class="math inline">\(5\)</span></td>
<td>0</td>
<td><span class="math inline">\(\emptyset\)</span></td>
</tr>
<tr class="even">
<td>3</td>
<td><span class="math inline">\(5\)</span></td>
<td>0</td>
<td><span class="math inline">\(\emptyset\)</span></td>
</tr>
</tbody>
</table>
<p>In our model, we assume the data is governed by a pdf, which is determined by
a specific parameter, represented as <span class="math inline">\(\boldsymbol{\theta}\)</span> within the parameter space <span class="math inline">\(\boldsymbol{\Omega}\)</span>.
The joint pdf of the data <span class="math inline">\(D\)</span> can be represented as follows:
<span class="math display">\[
f(D ; \boldsymbol{\theta}) = \prod_{i=1}^n f(D_i;\boldsymbol{\theta}) = \prod_{i=1}^n f(s_i,\delta_i,c_i;\boldsymbol{\theta}),
\]</span>
where <span class="math inline">\(s_i\)</span> is the observed system lifetime, <span class="math inline">\(\delta_i\)</span> is the observed event
indicator, and <span class="math inline">\(c_i\)</span> is the observed candidate set of the <span class="math inline">\(i\)</span> system.</p>
<p>This joint pdf tells us how likely we are to observe the particular data, <span class="math inline">\(D\)</span>, given
the parameter <span class="math inline">\(\boldsymbol{\theta}\)</span>. When we keep the data constant and allow the parameter
<span class="math inline">\(\boldsymbol{\theta}\)</span> to vary, we obtain what is called the likelihood function <span class="math inline">\(L\)</span>, defined as
<span class="math display">\[
L(\boldsymbol{\theta}) = \prod_{i=1}^n L_i(\boldsymbol{\theta})
\]</span>
where
<span class="math display">\[
L_i(\boldsymbol{\theta}) = f(s_i,\delta_i,c_i;\boldsymbol{\theta})
\]</span>
is the likelihood contribution of the <span class="math inline">\(i\)</span> system.</p>
For each type of data, right-censored data and masked component cause of
failure data, we will derive the <em>likelihood contribution</em> <span class="math inline">\(L_i\)</span>, which refers to the
part of the likelihood function that this particular piece of data contributes to.
We present the following theorem for the likelihood contribution model.
<p>In the following subsections, we prove this result for each type of masked data,
right-censored system lifetime data <span class="math inline">\((\delta_i = 0)\)</span> and masking of the
component cause of failure <span class="math inline">\((\delta_i = 1)\)</span>.</p>
</div>
<div id="candmod" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Masked Component Cause of Failure<a href="#candmod" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose a diagnostician is unable to identify the precise component cause of the
failure, e.g., due to cost considerations he or she replaced multiple components
at once, successfully repairing the system but failing to precisely identity
the failed component.
In this case, the cause of failure is said to be <em>masked</em>.</p>
<p>The unobserved component lifetimes may have many covariates, like ambient
operating temperature, but the only covariate we observe in our masked data
model are the system’s lifetime and additional masked data in the form of
a candidate set that is somehow correlated with the unobserved component
lifetimes.</p>
<p>The key goal of our analysis is to estimate the parameter <span class="math inline">\(\boldsymbol{\theta}\)</span>, which
maximize the likelihood of the observed data, and to estimate the precision and
accuracy of this estimate using the Bootstrap method.</p>
<p>To achieve this, we first need to assess the joint distribution of the system’s
continuous lifetime, <span class="math inline">\(T_i\)</span>, and the discrete candidate set, <span class="math inline">\(\mathcal{C}_i\)</span>, which
can be written as
<span class="math display">\[
f_{T_i,\mathcal{C}_i}(t_i,c_i;\boldsymbol{\theta}) = f_{T_i}(t_i;\boldsymbol{\theta})
    \Pr{}_{\!\boldsymbol{\theta}}\{\mathcal{C}_i = c_i | T_i = t_i\},
\]</span>
where <span class="math inline">\(f_{T_i}(t_i;\boldsymbol{\theta})\)</span> is the pdf of <span class="math inline">\(T_i\)</span> and
<span class="math inline">\(\Pr{}_{\!\boldsymbol{\theta}}\{\mathcal{C}_i = c_i | T_i = t_i\}\)</span> is the conditional
pmf of <span class="math inline">\(\mathcal{C}_i\)</span> given <span class="math inline">\(T_i = t_i\)</span>.</p>
<p>We assume the pdf <span class="math inline">\(f_{T_i}(t_i;\boldsymbol{\theta})\)</span> is known, but we do not have knowledge
of <span class="math inline">\(\Pr{}_{\!\boldsymbol{\theta}}\{\mathcal{C}_i = c_i | T_i = t_i\}\)</span>, i.e., the data generating
process for candidate sets is unknown.</p>
<p>However, it is critical that the masked data, <span class="math inline">\(\mathcal{C}_i\)</span>, is correlated with the
<span class="math inline">\(i\)</span> system. This way, the conditional distribution of <span class="math inline">\(\mathcal{C}_i\)</span>
given <span class="math inline">\(T_i = t_i\)</span> may provide information about <span class="math inline">\(\boldsymbol{\theta}\)</span>, despite our Statistical
interest being primarily in the series system rather than the candidate sets.</p>
To make this problem tractable, we assume a set of conditions that make it
unnecessary to estimate the generative processes for candidate sets.
The most important way in which <span class="math inline">\(\mathcal{C}_i\)</span> is correlated with the
<span class="math inline">\(i\)</span> system is given by assuming the following condition.
<p>Assuming Condition , <span class="math inline">\(\mathcal{C}_i\)</span> must contain the
index of the failed component, but we can say little else about what other
component indices may appear in <span class="math inline">\(\mathcal{C}_i\)</span>.</p>
<p>In order to derive the joint distribution of <span class="math inline">\(\mathcal{C}_i\)</span> and <span class="math inline">\(T_i\)</span> assuming
Condition , we take the following approach.
We notice that <span class="math inline">\(\mathcal{C}_i\)</span> and <span class="math inline">\(K_i\)</span> are statistically dependent.
We denote the conditional pmf of <span class="math inline">\(\mathcal{C}_i\)</span> given <span class="math inline">\(T_i = t_i\)</span> and
<span class="math inline">\(K_i = j\)</span> as
<span class="math display">\[
\Pr{}_{\!\boldsymbol{\theta}}\{\mathcal{C}_i = c_i | T_i = t_i, K_i = j\}.
\]</span></p>
<p>Even though <span class="math inline">\(K_i\)</span> is not observable in our masked data model, we can still
consider the joint distribution of <span class="math inline">\(T_i\)</span>, <span class="math inline">\(K_i\)</span>, and <span class="math inline">\(\mathcal{C}_i\)</span>.
By Theorem <a href="#thm:f-k-and-t">2.4</a>, the joint pdf of <span class="math inline">\(T_i\)</span> and <span class="math inline">\(K_i\)</span> is given by
<span class="math display">\[
f_{T_i,K_i}(t_i,j;\boldsymbol{\theta}) = h_j(t_i;\boldsymbol{\theta_j}) \prod_{l=1}^m R_l(t_i;\boldsymbol{\theta_l}),
\]</span>
where <span class="math inline">\(h_j(t_i;\boldsymbol{\theta_j})\)</span> and <span class="math inline">\(R_j(s_i;\boldsymbol{\theta_j})\)</span> are respectively the hazard
and reliability functions of the <span class="math inline">\(j\)</span> component.
Thus, the joint pdf of <span class="math inline">\(T_i\)</span>, <span class="math inline">\(K_i\)</span>, and <span class="math inline">\(\mathcal{C}_i\)</span> may be written as
<span class="math display">\[\begin{equation}
\label{eq:joint_pdf_t_k_c}
\begin{split}
f_{T_i,K_i,\mathcal{C}_i}(t_i,j,c_i;\boldsymbol{\theta})
    &amp;= f_{T_i,K_i}(t_i,k;\boldsymbol{\theta}) \Pr{}_{\!\boldsymbol{\theta}}\{\mathcal{C}_i=c_i|T_i=t_i,K_i=j\}\\
    &amp;= h_j(t_i;\boldsymbol{\theta_j}) \prod_{l=1}^m R_l(t_i;\boldsymbol{\theta_l})
    \Pr{}_{\!\boldsymbol{\theta}}\{\mathcal{C}_i=c_i|T_i=t_i,K_i=j\}.
\end{split}
\end{equation}\]</span>
We are going to need the joint pdf of <span class="math inline">\(T_i\)</span> and <span class="math inline">\(\mathcal{C}_i\)</span>, which
may be obtained by summing over the support <span class="math inline">\(\{1,\ldots,m\}\)</span> of <span class="math inline">\(K_i\)</span> in
Equation ,
<span class="math display">\[
f_{T_i,\mathcal{C}_i}(t_i,c_i;\boldsymbol{\theta}) = \prod_{l=1}^m R_l(t_i;\boldsymbol{\theta_l})
    \sum_{j=1}^m \biggl\{
        h_j(t_i;\boldsymbol{\theta_j}) \Pr{}_{\!\boldsymbol{\theta}}\{\mathcal{C}_i=c_i|T_i=t_i,K_i=j\}
    \biggr\}.
\]</span>
By Condition ,
<span class="math inline">\(\Pr{}_{\!\boldsymbol{\theta}}\{\mathcal{C}_i=c_i|T_i=t_i,K_i=j\} = 0\)</span> when <span class="math inline">\(K_i = j\)</span> and
<span class="math inline">\(j \notin c_i\)</span>, and so we may rewrite the joint pdf of <span class="math inline">\(T_i\)</span> and
<span class="math inline">\(\mathcal{C}_i\)</span> as
<span class="math display">\[\begin{equation}
\label{eq:part1}
f_{T_i,\mathcal{C}_i}(t_i,c_i;\boldsymbol{\theta}) = \prod_{l=1}^m R_l(t_i;\boldsymbol{\theta_l})
    \sum_{j \in c_i} \biggl\{
        h_j(t_i;\boldsymbol{\theta_j}) \Pr{}_{\!\boldsymbol{\theta}}\{\mathcal{C}_i=c_i|T_i=t_i,K_i=j\}
    \biggr\}.
\end{equation}\]</span></p>
<p>When we try to find an MLE of <span class="math inline">\(\boldsymbol{\theta}\)</span> (see Section <a href="#mle">4</a>), we
solve the simultaneous equations of the MLE and choose a solution
<span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> that is a maximum for the likelihood function.
When we do this, we find that <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> depends on the unknown
conditional pmf <span class="math inline">\(\Pr{}_{\!\boldsymbol{\theta}}\{\mathcal{C}_i=c_i|T_i=t_i,K_i=j\}\)</span>.
So, we are motivated to seek out more conditions (that approximately hold in
realistic situations) whose MLEs are independent of the pmf
<span class="math inline">\(\Pr{}_{\!\boldsymbol{\theta}}\{\mathcal{C}_i=c_i|T_i=t_i,K_i=j\}\)</span>.</p>
<p>In many industrial problems, masking generally
occurred due to time constraints and the expense of failure analysis <span class="citation">(Guess, Hodgson, and Usher <a href="#ref-Fran-1991" role="doc-biblioref">1991</a>)</span>.
In this setting, Condition  generally holds.</p>
<p>Assuming Conditions  and
,
<span class="math inline">\(\Pr{}_{\!\boldsymbol{\theta}}\{\mathcal{C}_i=c_i|T_i=t_i,K_i=j\}\)</span> may be factored out of the
summation in Equation , and thus the joint pdf of <span class="math inline">\(T_i\)</span> and
<span class="math inline">\(\mathcal{C}_i\)</span> may be rewritten as
<span class="math display">\[
f_{T_i,\mathcal{C}_i}(t_i,c_i;\boldsymbol{\theta}) =
    \Pr{}_{\!\boldsymbol{\theta}}\{\mathcal{C}_i=c_i|T_i=t_i,K_i=j&#39;\} \prod_{l=1}^m R_l(t_i;\boldsymbol{\theta_l})
    \sum_{j \in c_i} h_j(t_i;\boldsymbol{\theta_j})
\]</span>
where <span class="math inline">\(j&#39; \in c_i\)</span>.</p>
If <span class="math inline">\(\Pr{}_{\!\boldsymbol{\theta}}\{\mathcal{C}_i=c_i|T_i=t_i,K_i=j&#39;\}\)</span> is a function of
<span class="math inline">\(\boldsymbol{\theta}\)</span>, the MLEs are still dependent on the unknown
<span class="math inline">\(\Pr{}_{\!\boldsymbol{\theta}}\{\mathcal{C}_i=c_i|T_i=t_i,K_i=j&#39;\}\)</span>.
This is a more tractable problem, but we are primarily interested in the
situation where we do not need to know (nor estimate)
<span class="math inline">\(\Pr{}_{\!\boldsymbol{\theta}}\{\mathcal{C}_i=c_i|T_i=t_i,K_i=j&#39;\}\)</span> to find an MLE of
<span class="math inline">\(\boldsymbol{\theta}\)</span>. The last condition we assume achieves this result.
<p>When Conditions , ,
and  are satisfied, the joint pdf of <span class="math inline">\(T_i\)</span> and
<span class="math inline">\(\mathcal{C}_i\)</span> is given by
<span class="math display">\[
f_{T_i,\mathcal{C}_i}(t_i,c_i;\boldsymbol{\theta}) =
    \beta_i \prod_{l=1}^m R_l(t_i;\boldsymbol{\theta_l})
    \sum_{j \in c_i} h_j(t_i;\boldsymbol{\theta_j}).
\]</span>
When we fix the sample and allow <span class="math inline">\(\boldsymbol{\theta}\)</span> to vary, we obtain the
contribution to the likelihood <span class="math inline">\(L\)</span> from the <span class="math inline">\(i\)</span> observation
when the system lifetime is exactly known (i.e., <span class="math inline">\(\delta_i = 1\)</span>) but the
component cause of failure is masked by a candidate set <span class="math inline">\(c_i\)</span>:
<span class="math display">\[\begin{equation}
\label{eq:likelihood_contribution_masked}
L_i(\boldsymbol{\theta}) = \beta_i \prod_{l=1}^m R_l(t_i;\boldsymbol{\theta_l}) \sum_{j \in c_i} h_j(t_i;\boldsymbol{\theta_j}).
\end{equation}\]</span></p>
<p>To summarize this result, assuming Conditions ,
, and ,
if we observe an exact system failure time for the <span class="math inline">\(i\)</span>-th system (<span class="math inline">\(\delta_i = 1\)</span>),
but the component that failed is masked by a candidate set <span class="math inline">\(c_i\)</span>, then its likelihood
contribution is given by Equation .</p>
</div>
<div id="right-censored-data" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Right-Censored Data<a href="#right-censored-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As described in Section <a href="#like-model">3</a>, we observe realizations of
<span class="math inline">\((S_i,\delta_i,\mathcal{C}_i)\)</span> where <span class="math inline">\(S_i = \min\{T_i,\tau\}\)</span> is the
right-censored system lifetime, <span class="math inline">\(\delta_i = 1_{T_i &lt; \tau}\)</span> is
the event indicator, and <span class="math inline">\(\mathcal{C}_i\)</span> is the candidate set.</p>
In the previous section, we discussed the likelihood contribution from an
observation of a masked component cause of failure, i.e., <span class="math inline">\(\delta_i = 1\)</span>.
We now derive the likelihood contribution of a <em>right-censored</em> observation,
<span class="math inline">\(\delta_i = 0\)</span>, in our masked data model.
<p>When we combine the two likelihood contributions, we obtain the likelihood
contribution for the <span class="math inline">\(i\)</span> system shown in Theorem
,
<span class="math display">\[
L_i(\boldsymbol{\theta}) =
\begin{cases}
    \prod_{l=1}^m R_l(s_i;\boldsymbol{\theta_l})         &amp;\text{ if } \delta_i = 0\\
    \beta_i \prod_{l=1}^m R_l(t_i;\boldsymbol{\theta_l})
        \sum_{j\in c_i} h_j(s_i;\boldsymbol{\theta_j})   &amp;\text{ if } \delta_i = 1.
\end{cases}
\]</span>
We use this result in Section <a href="#mle">4</a> to derive the maximum likelihood
estimator (MLE) of <span class="math inline">\(\boldsymbol{\theta}\)</span>.</p>
</div>
<div id="identifiability-and-convergence-issues" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Identifiability and Convergence Issues<a href="#identifiability-and-convergence-issues" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In our likelihood model, masking and right-censoring can lead to issues related
to identifiability and flat likelihood regions.
Identifiability refers to the unique mapping of the model parameters to the
likelihood function, and lack of identifiability can lead
to multiple sets of parameters that explain the data equally well, making inference
about the true parameters challenging <span class="citation">(Lehmann and Casella <a href="#ref-lehmann1998theory" role="doc-biblioref">1998</a>)</span>, while
flat likelihood regions can complicate convergence <span class="citation">(Wu <a href="#ref-wu1983convergence" role="doc-biblioref">1983</a>)</span>.</p>
<p>In our simulation study, we address these challenges in a pragmatic way. Specifically,
failure to converge to a solution within a maximum of 125 iterations is interpreted as
evidence of the aforementioned issues, leading to the discarding of the sample, with
the process then repeated with a new synthetic sample. Note, however, that in Section
<a href="#boot">5</a> where we discuss the bias-corrected and accelerated (BCa) bootstrap
method for constructing confidence intervals, we do not discard any resamples.</p>
<p>This strategy helps ensure the robustness of the results, while acknowledging the
inherent complexities of likelihood-based estimation in models characterized by
masking and right-censoring.</p>
</div>
</div>
<div id="mle" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">4</span> Maximum Likelihood Estimation<a href="#mle" class="anchor-section" aria-label="Anchor link to header"></a></h1>
In our analysis, we use maximum likelihood estimation (MLE) to estimate the series
system parameter <span class="math inline">\(\boldsymbol{\theta}\)</span> from the masked data <span class="citation">(Bain and Engelhardt <a href="#ref-bain1992" role="doc-biblioref">1992</a>; Casella and Berger <a href="#ref-casella2002statistical" role="doc-biblioref">2002</a>)</span>.
The MLE finds parameter values that maximize the likelihood of the observed data
under the assumed model. A maximum likelihood estimate, <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>, is a
solution of
<span class="math display">\[\begin{equation}
\label{eq:mle}
L(\hat{\boldsymbol{\theta}}) = \max_{\boldsymbol{\theta }\in \boldsymbol{\Omega}} L(\boldsymbol{\theta}),
\end{equation}\]</span>
where <span class="math inline">\(L(\boldsymbol{\theta})\)</span> is the likelihood function of the observed data. For computational
efficiency and analytical simplicity, we work with the log-likelihood function,
denoted as <span class="math inline">\(\ell(\boldsymbol{\theta})\)</span>, instead of the likelihood function <span class="citation">(Casella and Berger <a href="#ref-casella2002statistical" role="doc-biblioref">2002</a>)</span>.
<p>The MLE, <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>, is often found by solving a system of equations derived from setting the derivative of the log-likelihood function to zero, i.e.,
<span class="math display">\[\begin{equation}
\label{eq:mle_eq}
\frac{\partial}{\partial \theta_j} \ell(\boldsymbol{\theta}) = 0,
\end{equation}\]</span>
for each component <span class="math inline">\(\theta_j\)</span> of the parameter <span class="math inline">\(\boldsymbol{\theta}\)</span> <span class="citation">(Bain and Engelhardt <a href="#ref-bain1992" role="doc-biblioref">1992</a>)</span>. When there’s no closed-form solution,
we resort to numerical methods like the Newton-Raphson method.</p>
<p>Assuming some regularity conditions, such as the likelihood function being identifiable, the MLE has many desirable
asymptotic properties that underpin statistical inference, namely that it is an asymptotically unbiased estimator
of the parameter <span class="math inline">\(\boldsymbol{\theta}\)</span> and it is normally distributed with a variance given by the inverse of the Fisher
Information Matrix (FIM) <span class="citation">(Casella and Berger <a href="#ref-casella2002statistical" role="doc-biblioref">2002</a>)</span>.
However, for smaller samples, these asymptotic properties may not yield accurate approximations. We propose to use
the bootstrap method to offer an empirical approach for estimating the sampling distribution of the MLE, in particular for
computing confidence intervals.</p>
</div>
<div id="boot" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">5</span> Bias-Corrected and Accelerated Bootstrap Confidence Intervals<a href="#boot" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>We utilize the non-parametric bootstrap to approximate the sampling distribution of
the MLE. In the non-parametric bootstrap, we resample from the observed data
with replacement to generate a bootstrap sample. The MLE is then computed for
the bootstrap sample. This process is repeated <span class="math inline">\(B\)</span> times, giving us <span class="math inline">\(B\)</span> bootstrap
replicates of the MLE. The sampling distribution of the MLE is then approximated
by the empirical distribution of the bootstrap replicates of the MLE.</p>
<p>The method we use to generate confidence intervals is known
as Bias-Corrected and Accelerated Bootstrap Confidence Intervals (BCa), which
applies two corrections to the standard bootstrap method:</p>
<ul>
<li><p>Bias correction: This adjusts for bias in the bootstrap distribution itself.
This bias is measured as the difference between the mean of the bootstrap distribution and the observed statistic.
It works by transforming the percentiles of the bootstrap distribution to correct for these issues.</p>
<p>This may be a useful transformation in our case since we are dealing with small samples and we have two potential
sources of bias: right-censoring and masking component cause of failure. They seem to have opposing effects
on the MLE, but the relationship is difficult to quantify.</p></li>
<li><p>Acceleration: This adjusts for the rate of change of the statistic as a function of the true, unknown parameter.
This correction is important when the shape of the statistic’s distribution changes with the true parameter.</p>
<p>Since we have a number of different shape parameters, <span class="math inline">\(k_1,\ldots,k_m\)</span>, we may expect the shape of the
distribution of the MLE to change as a function of the true parameter, making this correction potentially useful.</p></li>
</ul>
<p>Since we are primarly interested in generating confidence intervals for small samples for a
potentially biased MLE, the BCa method may be a good choice for our analysis. For more details
on BCa, see <span class="citation">(Efron <a href="#ref-efron1987better" role="doc-biblioref">1987</a>)</span>.</p>
<p>In our simulation study, we will assess the performance of the bootstrapped BCa
confidence intervals by computing the coverage probability of the confidence
intervals. A well-calibrated 95% confidence interval contains the true
value around 95% of the time. If the confidence interval is too narrow, it will have
a coverage probability less than 95%, which conveys a sort of false confidence
in the precision of the MLE. If the confidence interval is too wide, it will
have a coverage probability greater than 95%, which conveys a lack of confidence
in the precision of the MLE. We want confidence intervals to be as
narrow as possible while still having a coverage probability close to the
nominal level, 95%.</p>
<p>While the bootstrap method provides a robust and flexible tool for statistical
estimation, its effectiveness can be influenced by several factors
<span class="citation">(Efron and Tibshirani <a href="#ref-efron1994introduction" role="doc-biblioref">1994</a>)</span>. Firstly, instances of non-convergence in our bootstrap
samples were observed.
Such cases can occur when the estimation method, like the MLE used in our
analysis, fails to converge due to the specifics of the resampled data
<span class="citation">(Casella and Berger <a href="#ref-casella2002statistical" role="doc-biblioref">2002</a>)</span>. This issue can potentially introduce bias or
reduce the effective sample size of our bootstrap distribution.</p>
<p>Secondly, the bootstrap’s accuracy can be compromised with small sample sizes,
as the method relies on the law of large numbers to approximate the true sampling
distribution. For small datasets, the bootstrap samples might not adequately
represent the true variability in the data, leading to inaccurate results
<span class="citation">(Efron and Tibshirani <a href="#ref-efron1994introduction" role="doc-biblioref">1994</a>)</span>.</p>
<p>Thirdly, our data involves right censoring and a masking of the component cause
of failure when a system failure is observed. These aspects can cause certain data points or
trends to be underrepresented or not represented at all in our data, introducing
bias in the bootstrap distribution <span class="citation">(Klein and Moeschberger <a href="#ref-klein2005survival" role="doc-biblioref">2005</a>)</span>.</p>
<p>Despite these challenges, we found the bootstrap method useful in approximating
the sampling distribution of the MLE, taking care in interpreting the results,
particularly as it relates to coverage probabilities.</p>
</div>
<div id="weibull" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">6</span> Series System with Weibull Components<a href="#weibull" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The Weibull distribution, introduced by Waloddi Weibull in 1937, has been
instrumental in reliability analysis due to its ability to model a wide range
of failure behaviors. Reflecting on its utility, Weibull
modestly noted that it “[…] may sometimes render good service.” <span class="citation">(Abernethy <a href="#ref-Abernethy2006" role="doc-biblioref">2006</a>)</span>.
In the context of our study, we utilize the Weibull
to model a system as originating from Weibull components in a series configuration,
producing a specific form of the likelihood model described in Section <a href="#like-model">3</a>,
which deals with challenges such as right censoring and masked component cause of failure.</p>
<p>The <span class="math inline">\(j\)</span> component of the <span class="math inline">\(i\)</span> has a
lifetime distribution given by
<span class="math display">\[
    T_{i j} \sim \operatorname{Weibull}(k_j,\lambda_j) \qquad \text{for } i = 1,\ldots,n \text{ and } j = 1,\ldots,m,
\]</span>
where <span class="math inline">\(\lambda_j &gt; 0\)</span> is the scale parameter and <span class="math inline">\(k_j &gt; 0\)</span> is the shape parameter.
The <span class="math inline">\(j\)</span> component has a reliability function, pdf, and hazard function
given respectively by
<span class="math display">\[\begin{align}
    R_j(t;\lambda_j,k_j)
        &amp;= \exp\biggl\{-\biggl(\frac{t}{\lambda_j}\biggr)^{k_j}\biggr\},\\
    f_j(t;\lambda_j,k_j)
        &amp;= \frac{k_j}{\lambda_j}\biggl(\frac{t}{\lambda_j}\biggr)^{k_j-1}
        \exp\biggl\{-\left(\frac{t}{\lambda_j}\right)^{k_j} \biggr\},\\
    h_j(t;\lambda_j,k_j) \label{eq:weibull_haz}
        &amp;= \frac{k_j}{\lambda_j}\biggl(\frac{t}{\lambda_j}\biggr)^{k_j-1}.
\end{align}\]</span></p>
<p>The shape parameter of the Weibull distribtion is of particular importance:</p>
<ul>
<li><span class="math inline">\(k_j &lt; 1\)</span> indicates infant mortality. An example of how this might arise is
a result of defective components being weeded out early, and the remaining
components surviving for a much longer time.</li>
<li><span class="math inline">\(k_j = 1\)</span> indicates random failures (independent of age). An example of how
this might arise is a result of random shocks to the system, but otherwise
the system is age-independent.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></li>
<li><span class="math inline">\(k_j &gt; 1\)</span> indicates wear-out failures. An example of how this might arise is a
result of components wearing as they age</li>
</ul>
<p>We show that the lifetime of the series system composed of <span class="math inline">\(m\)</span> Weibull components
has a reliability, hazard, and probability density functions given by the following theorem.
::: {.theorem #sys_weibull}
The lifetime of a series system composed of <span class="math inline">\(m\)</span> Weibull components
has a reliability function, hazard function, and pdf respectively given by
<span class="math display">\[\begin{align}
\label{eq:sys_weibull_reliability_function}
R_{T_i}(t;\boldsymbol{\theta}) &amp;= \exp\biggl\{-\sum_{j=1}^{m}\biggl(\frac{t}{\lambda_j}\biggr)^{k_j}\biggr\},\\
\label{eq:sys_weibull_failure_rate_function}
h_{T_i}(t;\boldsymbol{\theta}) &amp;= \sum_{j=1}^{m} \frac{k_j}{\lambda_j}\biggl(\frac{t}{\lambda_j}\biggr)^{k_j-1},\\
\label{eq:sys_weibull_pdf}
f_{T_i}(t;\boldsymbol{\theta}) &amp;= \biggl\{
    \sum_{j=1}^m \frac{k_j}{\lambda_j}\left(\frac{t}{\lambda_j}\right)^{k_j-1}
\biggr\}
\exp
\biggl\{
    -\sum_{j=1}^m \bigl(\frac{t}{\lambda_j}\bigr)^{k_j}
\biggr\}.
\end{align}\]</span>
:::</p>
<div class="proof">
<p><span id="unlabeled-div-7" class="proof"><em>Proof</em>. </span>The proof for the reliability function follows from Theorem <a href="#thm:sys-reliability-function">2.1</a>,
<span class="math display">\[
R_{T_i}(t;\boldsymbol{\theta}) = \prod_{j=1}^{m} R_j(t;\lambda_j,k_j).
\]</span>
Plugging in the Weibull component reliability functions obtains the result
<span class="math display">\[\begin{align*}
R_{T_i}(t;\boldsymbol{\theta})
    = \prod_{j=1}^{m} \exp\biggl\{-\biggl(\frac{t}{\lambda_j}\biggr)^{k_j}\biggr\}
    = \exp\biggl\{-\sum_{j=1}^{m}\biggl(\frac{t}{\lambda_j}\biggr)^{k_j}\biggr\}.
\end{align*}\]</span>
The proof for the hazard function follows from Theorem <a href="#thm:sys-failure-rate">2.3</a>,
<span class="math display">\[\begin{align*}
h_{T_i}(t;\boldsymbol{\theta})
    = \sum_{j=1}^{m} h_j(t;\boldsymbol{\theta_j})
    = \sum_{j=1}^{m} \frac{k_j}{\lambda_j}\biggl(\frac{t}{\lambda_j}\biggr)^{k_j-1}
\end{align*}\]</span>
The proof for the pdf follows from Theorem <a href="#thm:sys-pdf">2.2</a>. By definition,
<span class="math display">\[
f_{T_i}(t;\boldsymbol{\theta}) = h_{T_i}(t;\boldsymbol{\theta}) R_{T_i}(t;\boldsymbol{\theta}).
\]</span>
Plugging in the failure rate and reliability functions given respectively by
Equations  and
 completes the proof.</p>
</div>
<div id="reliability-1" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Reliability<a href="#reliability-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In Section <a href="#reliability">2.2</a>, we discussed the concept of reliability.
In the case of Weibull components, the MTTF of the <span class="math inline">\(j\)</span>
component is given by
<span class="math display">\[\begin{equation}
\label{eq:mttf-weibull}
\text{MTTF}_j = \lambda_j \Gamma\biggl(1 + \frac{1}{k_j}\biggr),
\end{equation}\]</span>
where <span class="math inline">\(\Gamma\)</span> is the gamma function.</p>
<p>We mentioned that the MTTF can sometimes be a poor measure of reliability, e.g.,
the MTTF and the probability of failing early can be large. The Weibull is a good
example of this phenomenon. If <span class="math inline">\(k &gt; 1\)</span>, the Weibull is a fat-tailed distribution,
and it can exhibit both a large MTTF and a high probability of failing early.</p>
<p>Components may have similar MTTFs, but some components may be more likely to fail
early and others may be more likely to fail late, depending upon their failure
characterstics (shape parameters), and so the probability of component failure given by
Equation  is a useful measure of component reliability compared to
the other components in the system.</p>
<p>In a well-designed series system, the component failure characteristics are similar:
they have a similar MTTF and a similar probability of being the component cause of
failure, i.e., they have similar shapes and scales, so that system failures are not
dominated by some subset of components.</p>
</div>
<div id="sys-weibull-like" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Likelihood Model<a href="#sys-weibull-like" class="anchor-section" aria-label="Anchor link to header"></a></h2>
In Section <a href="#like-model">3</a>, we discussed two separate kinds of likelihood
contributions, masked component cause of failure data (with exact system failure
times) and right-censored data. The likelihood contribution of the
<span class="math inline">\(i\)</span> system is given by the following theorem.
Taking the log of the likelihood contribution function obtains the following result.
<p>See Appendix <a href="#app-weibull-loglik-r">A</a> for the R code that implements the log-likelihood function
for the series system with Weibull components.</p>
<p>We find an MLE by solving ,
i.e., a point <span class="math inline">\(\boldsymbol{\hat\theta} = (\hat{k}_1,\hat{\lambda}_1,\ldots,\hat{k}_m,\hat{\lambda}_m)\)</span> satisfying
<span class="math inline">\(\nabla_{\theta} \ell(\boldsymbol{\hat\theta}) = \boldsymbol{0}\)</span>, where <span class="math inline">\(\nabla_{\boldsymbol{\theta}}\)</span>
is the gradient of the log-likelihood function (score) with respect to <span class="math inline">\(\boldsymbol{\theta}\)</span>.</p>
<p>To solve this system of equations, we use the Newton-Raphson method, which requires
the score and the Hessian of the log-likelihood function.
We analytically derive the score since it is useful to have for the Newton-Raphson
method, but we do not do the same for the Hessian of the log-likelihood for the following reasons:</p>
<ol style="list-style-type: decimal">
<li><p>The gradient is easy to derive, and it is useful to have for
computing gradients efficiently and accurately, which will be useful for
numerically approximating the Hessian.</p></li>
<li><p>The Hessian is tedious and error prone to derive, and Newton-like methods
often do not require the Hessian to be explicitly computed.</p></li>
</ol>
The following theorem derives the score function.
<p>The result follows from taking the partial derivatives of the log-likelihood
contribution of the <span class="math inline">\(i\)</span>-th system given by Equation
. It is a tedious calculation so the proof
has been omitted, but the result has been verified by using a very precise numerical
approximation of the gradient.</p>
<p>By the linearity of differentiation, the gradient of a sum of functions is
the sum of their gradients, and so the score function conditioned on the entire
sample is given by
<span class="math display">\[\begin{equation}
\label{eq:weibull_series_score}
\nabla \ell(\boldsymbol{\theta}) = \sum_{i=1}^n \nabla \ell_i(\boldsymbol{\theta}).
\end{equation}\]</span></p>
</div>
<div id="reduced-weibull" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Weibull Series System: Homogeneous Shape Parameters<a href="#reduced-weibull" class="anchor-section" aria-label="Anchor link to header"></a></h2>
A series system composed of Weibull components is not generally Weibull unless the
shape parameters of the components are homogeneous.
<div class="theorem">
<p><span id="thm:unlabeled-div-8" class="theorem"><strong>Theorem 6.1  </strong></span>If a series system has Weibull components with homogeneous shape parameters, the component
cause of failure is conditionally independent of the system failure time:
<span class="math display">\[
    \Pr\{K_i = j | T_i = t_i \} = \Pr\{K_i = j\} = \frac{\lambda_j^{-k}}{\sum_{l=1}^{m} \lambda_l^{-k}}.
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-9" class="proof"><em>Proof</em>. </span>By Theorem <a href="#thm:prob-k-given-t">2.6</a>, the conditional probability of the <span class="math inline">\(j\)</span> component being the
cause of failure given the system failure time is given by
<span class="math display">\[\begin{align*}
\Pr\{K_i = j | T_i = t\}
    &amp;= \frac{f_{K_i, T_i}(j, t;\boldsymbol{\theta})}{f_{T_i}(t;\boldsymbol{\theta})}
    = \frac{h_j(t;k,\lambda_j) R_{T_i}(t;\boldsymbol{\theta})}
        {h_{T_i}(t;\boldsymbol{\theta_j}) R_{T_i}(t;\boldsymbol{\theta})}\\
    &amp;= \frac{h_j(t;k,\lambda_j)}{\sum_{l=1}^m h_l(t;k,\lambda_l)}
    = \frac{\frac{k}{\lambda_j}\bigl(\frac{t}{\lambda_j}\bigr)^{k-1}}
        {\sum_{l=1}^m \frac{k}{\lambda_l}\bigl(\frac{t}{\lambda_l}\bigr)^{k-1}}
    = \frac{\bigl(\frac{1}{\lambda_j}\bigr)^k}
        {\sum_{l=1}^m \bigl(\frac{1}{\lambda_l}\bigr)^k}.
\end{align*}\]</span></p>
</div>
<p>If we have prior knowledge that the shape parameters are sufficiently homogenous, it may
be useful to simplify the likelihood model by assuming the shape parameters are identical,
simplifying the series system to Weibull, facilitating analysis and interpretation.
According to the bias-variance trade-off, we expect the MLE to be more biased but
have lower sampling variance.</p>
<p>We denote the full model log-likelihood function by <span class="math inline">\(\ell_F\)</span> and the reduced model log-likelihood
by <span class="math inline">\(\ell_R\)</span>. The reduced model is obtained by setting the shape parameter of each component to
be the same, i.e., <span class="math inline">\(k_1 = \cdots = k_m = k\)</span>. Thus, the reduced model log-likelihood function is given by
<span class="math display">\[
\ell_R(k, \lambda_1, \lambda_2, \cdots, \lambda_m) =
        \ell_F(k, \lambda_1, k, \lambda_2, \ldots, k, \lambda_m),
\]</span>
The same may be done for the score and hessian of the log-likelihood functions.</p>
</div>
</div>
<div id="sim-study" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">7</span> Simulation Study: Series System with Weibull Components<a href="#sim-study" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In this section, we conduct a simulation study to assess the performance
of the MLE for the full likelihood model defined in Section <a href="#weibull">6</a>.
In this simulation study, we assess the sensitivity of the MLE to
various simulation scenarios. In particular, we assess two important
properties of the MLE with respect to a scenario:</p>
<ol style="list-style-type: decimal">
<li><p>Accuracy (Bias): How close is the expected value of the MLE to the true
parameter values? If the expected value of the MLE is close to the true
parameter values, the accuracy is high.</p></li>
<li><p>Precision: How much does the MLE vary from sample to sample? We measure
this by assessing the 95% confidence intervals (BCa, Bias-Corrected and
accelerated). If the confidence intervals are both small and have good
coverage probability (the proportion of confidence intervals that contain
the true parameter values), then the MLE is precise.</p></li>
</ol>
<p>We begin by specifying the parameters of the series system that will be
the central object of our simulation study. We consider the data in
<span class="citation">(Guo, Niu, and Szidarovszky <a href="#ref-Huairu-2013" role="doc-biblioref">2013</a>)</span>, in which they study the reliability of a series system with
three components. They fit Weibull components in a series configuration to
the data, resulting in an MLE with shape and scale estimates given by the
first three components in Table . To make the model
slightly more complex, we add two more components to this series system,
with shape and scale parameters given by the last two components in Table
. We will refer to this system as the <strong>base</strong> system.</p>
<p>In Section <a href="#reliability">2.2</a>, we defined a well-designed series
system as one that consists of components with similar reliabilities, where we define
reliability in two ways, the mean time to failure (MTTF) and the probability that a
specific component will be the cause of failure. All things else being equal,
components with long MTTFs and with near uniform probability of being the component
cause of failure is preferrable, otherwise we have a weak link in the system.</p>
<p>The base system defined in Table  satisfies this definition
of being a well-designed system. We see that there are no components that are
significantly less reliable than any of the others, component 1 being the most reliable
and component 3 being the least reliable. This is a result of the scales and shapes
being similar for each component. In addition, the shapes are larger than <span class="math inline">\(1\)</span>, which
means components are unlikely to fail early.</p>
<table>
<caption>
<span id="tab:series-sys">Table 7.1: </span>Weibull Components in Series Configuration
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Shape (<span class="math inline">\(k_j\)</span>)
</th>
<th style="text-align:right;">
Scale (<span class="math inline">\(\lambda_j\)</span>)
</th>
<th style="text-align:right;">
MTTF<span class="math inline">\(_j\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(\Pr\{K_i = j\}\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(R_j(\tau;k_j,\lambda_j)\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Component 1
</td>
<td style="text-align:right;">
1.2576
</td>
<td style="text-align:right;">
994.3661
</td>
<td style="text-align:right;">
924.869
</td>
<td style="text-align:right;">
0.169
</td>
<td style="text-align:right;">
0.744
</td>
</tr>
<tr>
<td style="text-align:left;">
Component 2
</td>
<td style="text-align:right;">
1.1635
</td>
<td style="text-align:right;">
908.9458
</td>
<td style="text-align:right;">
862.157
</td>
<td style="text-align:right;">
0.207
</td>
<td style="text-align:right;">
0.698
</td>
</tr>
<tr>
<td style="text-align:left;">
Component 3
</td>
<td style="text-align:right;">
1.1308
</td>
<td style="text-align:right;">
840.1141
</td>
<td style="text-align:right;">
803.564
</td>
<td style="text-align:right;">
0.234
</td>
<td style="text-align:right;">
0.667
</td>
</tr>
<tr>
<td style="text-align:left;">
Component 4
</td>
<td style="text-align:right;">
1.1802
</td>
<td style="text-align:right;">
940.1342
</td>
<td style="text-align:right;">
888.237
</td>
<td style="text-align:right;">
0.196
</td>
<td style="text-align:right;">
0.711
</td>
</tr>
<tr>
<td style="text-align:left;">
Component 5
</td>
<td style="text-align:right;">
1.2034
</td>
<td style="text-align:right;">
923.1631
</td>
<td style="text-align:right;">
867.748
</td>
<td style="text-align:right;">
0.195
</td>
<td style="text-align:right;">
0.711
</td>
</tr>
<tr>
<td style="text-align:left;">
Series System
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
222.884
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
0.175
</td>
</tr>
</tbody>
</table>
<div id="data-gen-proc" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> Data Generating Process<a href="#data-gen-proc" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this section, we describe the data generating process for our simulation studies.
It consists of three parts: the series system, the candidate set model, and the
right-censoring model.</p>
<div id="series-system-lifetime" class="section level3 unnumbered hasAnchor" number="">
<h3>Series System Lifetime<a href="#series-system-lifetime" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We generate data from a Weibull series system with <span class="math inline">\(m\)</span> components.
As described in Section <a href="#weibull">6</a>, the <span class="math inline">\(j\)</span> component
of the <span class="math inline">\(i\)</span> system has a lifetime distribution given by
<span class="math display">\[
    T_{i j} \sim \operatorname{Weibull}(k_j, \lambda_j)
\]</span>
and the lifetime of the series system composed of <span class="math inline">\(m\)</span> Weibull components
is defined as
<span class="math display">\[
    T_i = \min\{T_{i 1}, \ldots, T_{i m}\}.
\]</span>
To generate a data set, we first generate the <span class="math inline">\(m\)</span> component failure times,
by efficiently sampling from their respective distributions, and we then set
the failure time <span class="math inline">\(t_i\)</span> of the system to the minimum of the component failure times.</p>
</div>
<div id="right-censoring-model" class="section level3 unnumbered hasAnchor" number="">
<h3>Right-Censoring Model<a href="#right-censoring-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We employ a simple right-censoring model, where the right-censoring time
<span class="math inline">\(\tau\)</span> is fixed at some known value, e.g., an experiment is run for a fixed
amount of time <span class="math inline">\(\tau\)</span>, and all systems that have not failed by the end of the
experiment are right-censored. The censoring time <span class="math inline">\(S_i\)</span> of the
<span class="math inline">\(i\)</span> system is thus given by
<span class="math display">\[
    S_i = \min\{T_i, \tau\}.
\]</span>
So, after we generate the system failure time <span class="math inline">\(T_i\)</span>, we generate the censoring
time <span class="math inline">\(S_i\)</span> by taking the minimum of <span class="math inline">\(T_i\)</span> and <span class="math inline">\(\tau\)</span>.
In our simulation study, we paramaterize the right-censoring time <span class="math inline">\(\tau\)</span> by the
quantile <span class="math inline">\(q = 0.825\)</span> of the series system,
<span class="math display">\[
    \tau = F_{T_i}^{-1}(q).
\]</span>
This means that <span class="math inline">\(82.5\%\)</span> of the series systems are expected to fail before time <span class="math inline">\(\tau\)</span>
and <span class="math inline">\(17.5\%\)</span> of the series are expected to be right-censored. To solve for the <span class="math inline">\(82.5\%\)</span>
quantile of the series system, we define the function <span class="math inline">\(g\)</span> as
<span class="math display">\[
g(\tau) = F_{T_i}(\tau;\boldsymbol{\theta}) - q
\]</span>
and find its root using the Newton-Raphson method. See Appendix <a href="#app-series-quantile">E</a> for the R code that
implements this procedure.</p>
</div>
<div id="masking-model-for-component-cause-of-failure" class="section level3 unnumbered hasAnchor" number="">
<h3>Masking Model for Component Cause of Failure<a href="#masking-model-for-component-cause-of-failure" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We must generate data that satisfies the masking conditions described in
Section <a href="#candmod">3.1</a>.
There are many ways to satisfying the masking conditions. We choose the simplest
method, which we call the <em>Bernoulli candidate set model</em>. In this model, each
non-failed component is included in the candidate set with
a fixed probability <span class="math inline">\(p\)</span>, independently of all other components and independently
of <span class="math inline">\(\boldsymbol{\theta}\)</span>, and the failed component is always included in the candidate set.
See <a href="#app-cand-model-r">D</a>} for the R code that implements this model.</p>
</div>
</div>
<div id="simulation-scenarios" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> Simulation Scenarios<a href="#simulation-scenarios" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We define a simulation scenario to be some combination of <span class="math inline">\(n\)</span> (sample size),
<span class="math inline">\(p\)</span> (masking probability in our Bernoulli candidate set model), <span class="math inline">\(k_3\)</span>
(shape parameter of the third component), <span class="math inline">\(\lambda_3\)</span> (scale parameter of the
third component), and <span class="math inline">\(q\)</span> (right-censoring quantile). We are interested in
choosing a small number of scenarios that are representative of real-world
scenarios and that are interesting to analyze.</p>
<p>Here is an outline of the simulation study for a particular scenario:</p>
<ol style="list-style-type: decimal">
<li><p>Fix a combination of simulation parameters to some value, and vary the remaining
parameters. For example, if we want to assess how the sampling distribution of
the MLE changes with respect to sample size, we might choose some particular
values for <span class="math inline">\(p\)</span>, <span class="math inline">\(k_3\)</span>, <span class="math inline">\(\lambda_3\)</span>, and <span class="math inline">\(q\)</span>, and vary the sample size <span class="math inline">\(n\)</span> over the
desired range.</p></li>
<li><p>Simulate <span class="math inline">\(R \geq 300\)</span> datasets from the Data Generating Process (DGP) described in
Section <a href="#data-gen-proc">7.1</a> and compute an MLE for each dataset. We choose <span class="math inline">\(R\)</span> to be
large enough so that the sampling distribution of the MLE is well approximated by
the empirical distribution of the <span class="math inline">\(R\)</span> MLEs.</p></li>
<li><p>For each of these <span class="math inline">\(R\)</span> MLEs, compute some function of the MLE, like the BCa confidence
intervals or the likelihood ratio test statistic. This will give us <span class="math inline">\(R\)</span> statistics
as a Monte-carlo estimate of the sampling distribution of the statistic.</p></li>
<li><p>Use the <span class="math inline">\(R\)</span> statistics to estimate some property of the sampling distribution of the
statistic, e.g., the mean of the MLE or the coverage probability of the BCa confidence
intervals, with respect to the parameter(s) we are varying in the scenario, e.g.,
assess how the coverage probability of the BCa confidence intervals changes with
respect to sample size.</p></li>
<li><p>Visualize the results and assess the behavior of estimator under the chosen scenario.</p></li>
</ol>
<p>For how we run a simulation scenario, see Appendix <a href="#app-sim-study-r">C</a>.</p>
</div>
<div id="effect-censoring" class="section level2 hasAnchor" number="7.3">
<h2><span class="header-section-number">7.3</span> Scenario: Assessing the Impact of Right-Censoring<a href="#effect-censoring" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this scenario, we use the well-designed series system described in Table ,
and we vary the right-censoring quantile (<span class="math inline">\(q\)</span>) from <span class="math inline">\(60\%\)</span> to <span class="math inline">\(100\%\)</span>
(no right-censoring), with a component cause of failure masking
probability of <span class="math inline">\(21.5\%\)</span> and sample size <span class="math inline">\(n = 100\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:q-vs-stats"></span>
<embed src="image/5_system_tau_fig.pdf" title="Right-Censoring Quantile vs MLE ($p = 0.215, n = 100$)" width="100%" type="application/pdf" />
<p class="caption">
Figure 7.1: Right-Censoring Quantile vs MLE (<span class="math inline">\(p = 0.215, n = 100\)</span>)
</p>
</div>
<p>When a right-censoring event occurs, in order to increase the likelihood of the data, the MLE
is nudged in a direction that increases the probability of a right-censoring event at time <span class="math inline">\(\tau\)</span>,
which is given by <span class="math inline">\(R_{T_i}(t;\boldsymbol{\theta})\)</span>, representing a source of bias in the estimate.</p>
<p>To increase <span class="math inline">\(R_{T_i}(\tau)\)</span>, we move in the direction (gradient) of these partial derivatives.
The partial derivatives of <span class="math inline">\(R_{T_i}(\tau)\)</span>
are given by
<span class="math display">\[\begin{align*}
\frac{\partial R_{T_i}(\tau)}{\partial \lambda_j} &amp;= R_{T_i}(\tau;\boldsymbol{\theta}) \left(\frac{\tau}{\lambda_j}\right)^{k_j} \frac{k_j}{\lambda_j},\\
\frac{\partial R_{T_i}(\tau)}{\partial k_j}       &amp;= R_{T_i}(\tau;\boldsymbol{\theta}) \left(\frac{\tau}{\lambda_j}\right)^{k_j} \left(\log \lambda_j - \log \tau\right),
\end{align*}\]</span>
for <span class="math inline">\(j = 1, \ldots, m\)</span>. We see that these partial derivatives are related to the score of a right-censored likelihood contribution in
Theorem . Let us analyze these partial derivatives:</p>
<ul>
<li><p>As the right-censoring quantile <span class="math inline">\(q\)</span> increases (<span class="math inline">\(\tau\)</span> increases), <span class="math inline">\(R_{T_i}(\tau;\boldsymbol{\theta})\)</span>
decreases, and so the effect right-censoring has on the MLE decreases. This is what we see
in Figure .</p></li>
<li><p>The partial derivatives with respect to the scale parameters are always positive, so right-censoring positively bias the scale parameter
estimates to make right-censoring events more likely. The more right-censoring, the more the positive bias. We see this in Figure
, where the bias of the MLE for the scale parameter decreases as we decrease the probability (<span class="math inline">\(1-q\)</span>) of a right-censoring event.</p></li>
<li><p>The partial derivative with respect to the shape parameter of the <span class="math inline">\(j\)</span> component, <span class="math inline">\(k_j\)</span>, is
non-negative if <span class="math inline">\(\lambda_j \geq \tau\)</span> and otherwise negative. In our well-designed series system, the scale parameters
are large compared to most of the right-censoring times for <span class="math inline">\(\tau(q)\)</span>, so the MLE nudges the shape parameter estimates
in a positive direction to increase the probability of a right-censoring event <span class="math inline">\(R_{T_i}(\tau)\)</span> at time <span class="math inline">\(\tau\)</span>. We see this
in Figure , where the shape parameter estimates are positively biased for most of the quantiles
<span class="math inline">\(q\)</span>.</p></li>
</ul>
<div id="key-observations" class="section level3 hasAnchor" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> Key Observations<a href="#key-observations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="coverage-probability-cp" class="section level5 unnumbered hasAnchor" number="">
<h5>Coverage Probability (CP)<a href="#coverage-probability-cp" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The CP is well-calibrated, obtaining a value near the
nominal 95% level across different right-censoring quantiles. This suggests that the
bootstrapped CIs will contain the true value of the parameters with the specified confidence
level. The CIs are neither too wide nor too narrow.</p>
</div>
<div id="dispersion-of-mles" class="section level5 unnumbered hasAnchor" number="">
<h5>Dispersion of MLEs<a href="#dispersion-of-mles" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The shaded regions representing the 95% probability range of
the MLEs get narrower as the right-censoring quantile increases. This is an indicator of the
increased precision in the estimates as more data is available due to decreased
censoring.</p>
</div>
<div id="iqr-of-bootstrapped-cis" class="section level5 unnumbered hasAnchor" number="">
<h5>IQR of Bootstrapped CIs<a href="#iqr-of-bootstrapped-cis" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The IQR (vertical blue bars) reduces with an increase in
sample size. This suggests that the bootstrapped CIs are getting more consistent and
focused around a narrower range with larger samples while maintaining a good coverage
probability. As we get more data, the bootstrapped CIs are more likely to be closer
to each other and the true value of the parameters.</p>
<p>For small right-censoring quantiles (small right-censoring times), they are quite
large, but to maintain well-calibrated CIs, this was necessary. The estimator is quite
sensitive to the data, and so the bootstrapped CIs are quite wide to account for this
sensitivity when the sample contains insufficient information due to censoring.</p>
</div>
<div id="bias-of-mles" class="section level5 unnumbered hasAnchor" number="">
<h5>Bias of MLEs<a href="#bias-of-mles" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The red dashed line indicating the mean of MLEs initially is quite biased,
but quickly diminshes to neglible levels for scale parameters. The bias for the shape
parameters never reach zero, but this is potentially due to masking. At a larger sample
size, we anticipate the bias in the shape estimates would also decrease to zero.</p>
</div>
</div>
</div>
<div id="effect-samp-size" class="section level2 hasAnchor" number="7.4">
<h2><span class="header-section-number">7.4</span> Scenario: Assessing the Impact of Sample Size<a href="#effect-samp-size" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this scenario, we use the well-designed series system described in Table . We fix the masking probability to <span class="math inline">\(p = 0.215\)</span> (moderate masking),
we fix the right-censoring quantile to <span class="math inline">\(q = 0.825\)</span> (moderate censoring), and we vary the sample
size <span class="math inline">\(n\)</span> from <span class="math inline">\(50\)</span> (small sample size) to <span class="math inline">\(1000\)</span> (very large sample size).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:samp-size-n-vs-stats"></span>
<embed src="image/5_system_samp_size_fig.pdf" title="Sample Size vs MLEs ($p = 0.215, q = 0.825$)" width="100%" type="application/pdf" />
<p class="caption">
Figure 7.2: Sample Size vs MLEs (<span class="math inline">\(p = 0.215, q = 0.825\)</span>)
</p>
</div>
<p>In Figure , we show the effect of the sample size <span class="math inline">\(n\)</span> on the MLEs
for the shape and scale parameters. The top four plots only show the effect on the MLEs for the
shape and scale parameters of components <span class="math inline">\(1\)</span> and <span class="math inline">\(4\)</span>, since the rest were essentially identical,
and the bottom two plots show the coverage probabilities for all parameters.</p>
<div id="key-observations-1" class="section level3 hasAnchor" number="7.4.1">
<h3><span class="header-section-number">7.4.1</span> Key Observations<a href="#key-observations-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="coverage-probability-cp-1" class="section level5 unnumbered hasAnchor" number="">
<h5>Coverage Probability (CP)<a href="#coverage-probability-cp-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The CP is well-calibrated, obtaining a value near the
nominal <span class="math inline">\(95\%\)</span> level across different sample sizes. This suggests that the bootstrapped
CIs will contain the true value of the shape parameter with the specified confidence
level. The CIs are neither too wide nor too narrow.</p>
</div>
<div id="dispersion-of-mles-1" class="section level5 unnumbered hasAnchor" number="">
<h5>Dispersion of MLEs<a href="#dispersion-of-mles-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The shaded regions representing the <span class="math inline">\(95\%\)</span> probability range of
the MLEs get narrower as the sample size increases. This is an indicator of the
increased precision in the estimates when provided with more data. This is consistent
with the asymptotic properties of the MLE when the regularity conditions are satisfied,
e.g., converges in probability to the true value of the parameter as <span class="math inline">\(n\)</span> goes to infinity.</p>
</div>
<div id="iqr-of-bootstrapped-cis-1" class="section level5 unnumbered hasAnchor" number="">
<h5>IQR of Bootstrapped CIs<a href="#iqr-of-bootstrapped-cis-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The IQR (vertical blue bars) reduces with an increase in
sample size. This suggests that the bootstrapped CIs are getting more consistent and
focused around a narrower range with larger samples while maintaining a good coverage
probability. As we get more data, the bootstrapped CIs are more likely to be closer
to each other and the true value of the scale parameter.</p>
<p>For small sample sizes, they are quite large, but to maintain well-calibrated CIs, this
was necessary. The estimator is quite sensitive to the data, and so the bootstrapped
CIs are quite wide to account for this sensitivity when the sample size is small and
not necessarily representative of the true distribution.</p>
</div>
<div id="bias-of-mles-for-scales" class="section level5 unnumbered hasAnchor" number="">
<h5>Bias of MLEs for Scales<a href="#bias-of-mles-for-scales" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The red dashed line indicating the mean of MLEs remains stable across
different sample sizes and close to the true value, suggesting that the scale MLEs are
reasonably unbiased.</p>
</div>
<div id="bias-of-mles-for-shapes" class="section level5 unnumbered hasAnchor" number="">
<h5>Bias of MLEs for Shapes<a href="#bias-of-mles-for-shapes" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The red dashed line is the mean of shape MLEs. Unlike the scale MLEs,
we see that for small samples, particularly less than <span class="math inline">\(200\)</span>, we observe a significant
amount of positive bias for shape MLEs. The MLE for the shape parameters in this
scenario appear to be more sensitive to the data than the scale parameters.</p>
<p>This scenario successfully illustrates the importance of sample size in estimating parameters.
The findings align with statistical theory and provide insights into the behavior of these estimators
for different sample sizes. In particular, it highlights the sensitivity of the shape parameter
estimates to right-censoring and masking for small sample sizes and the importance of having
sufficient data to overcome these effects.</p>
</div>
</div>
</div>
<div id="p-vs-mttf" class="section level2 hasAnchor" number="7.5">
<h2><span class="header-section-number">7.5</span> Scenario: Assessing the Impact of Masking Probability for Component Cause of Failure<a href="#p-vs-mttf" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this scenario, we use the well-designed series system described in
Table . We fix the sample size to <span class="math inline">\(n = 90\)</span> (reasonable sample size) and
we fix the right-censoring quantile to <span class="math inline">\(q = 0.825\)</span>, and we vary the masking probability
from <span class="math inline">\(p\)</span> from <span class="math inline">\(0.1\)</span> (very slight masking the component cause of failure) to <span class="math inline">\(0.85\)</span>
(extreme masking of the component cause of failure).</p>
<p>In Figure , we show the effect of the masking probability
<span class="math inline">\(p\)</span> on the MLE for the shape and scale parameters. The top four plots only show the effect
on the MLEs for the the shape and scale parameters of components <span class="math inline">\(1\)</span> and <span class="math inline">\(4\)</span>, since the
rest were essentially identical, and the bottom two plots show the coverage probabilities for
all parameters.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:masking-prob-vs-stats"></span>
<embed src="image/5_system_prob_fig.pdf" title="Component Cause of Failure Masking ($p$) vs MLE" type="application/pdf" />
<p class="caption">
Figure 7.3: Component Cause of Failure Masking (<span class="math inline">\(p\)</span>) vs MLE
</p>
</div>
<div id="key-observations-2" class="section level3 hasAnchor" number="7.5.1">
<h3><span class="header-section-number">7.5.1</span> Key Observations<a href="#key-observations-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="coverage-probability-cp-2" class="section level5 unnumbered hasAnchor" number="">
<h5>Coverage Probability (CP)<a href="#coverage-probability-cp-2" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>For the scale parameters, the <span class="math inline">\(95\%\)</span> CI is well-calibrated
for Bernulli masking probabilities up to <span class="math inline">\(p = 0.725\)</span>, which is really quite significant,
obtaining coverages over <span class="math inline">\(90\%\)</span>, but drops precipitously after that point.<br />
For the shape parameters, the <span class="math inline">\(95\%\)</span> CI is well-calibrated for masking probabilities only
up to <span class="math inline">\(p = 0.4\)</span>, which is still large, obtaining coverages generally over <span class="math inline">\(90%\)</span>, but
begins to drop slowly after that point.</p>
<p>The BCa confidence intervals are well-calibrated for most realistic
masking probabilities, constructing CIs that are neither too wide nor too narrow,
but when the masking is severe and the sample size is small, one should
take the CIs with a grain of salt.</p>
</div>
<div id="dispersion-of-mles-2" class="section level5 unnumbered hasAnchor" number="">
<h5>Dispersion of MLEs<a href="#dispersion-of-mles-2" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The shaded regions representing the <span class="math inline">\(95\%\)</span> quantile of
the MLEs become wider as the masking probability increases. This is an indicator of the
decreased precision in the estimates when provided with more ambiguous data about the
component cause of failure. However, even for fairly significant Bernoulli masking,
<span class="math inline">\(p \leq 0.55\)</span>, the <span class="math inline">\(95\%\)</span> quantiles are narrow and the CP is
well-calibrated, indicating that the MLEs are still precise and accurate.</p>
</div>
<div id="iqr-of-bootstrapped-cis-2" class="section level5 unnumbered hasAnchor" number="">
<h5>IQR of Bootstrapped CIs<a href="#iqr-of-bootstrapped-cis-2" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The IQR (vertical blue bars) show that the bootstrapped BCa
CIs are becoming more spread out as the masking probability increases. They are also
asymmetric, with the lower bound being more spread out than the upper bound, but this
is consistent with the actual behavior of the dispersion of the MLEs, which exhibits
the same pattern. The width of the CIs consistently increase as the masking probability
increases, which we intuitively expected given the increased uncertanity about the
component cause of failure.
After a Bernoulli masking probability of <span class="math inline">\(p \approx 0.5\)</span>, the width of the CIs rapidly increase,
which is apparently necessary for the CPs to remain well-calibrated.</p>
</div>
<div id="bias-of-mles-1" class="section level5 unnumbered hasAnchor" number="">
<h5>Bias of MLEs<a href="#bias-of-mles-1" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The red dashed line indicating the mean of the MLEs remains
stable across different masking probabilities, only showing a significant positive bias
when the masking probability <span class="math inline">\(p\)</span> becomes quite significant.</p>
</div>
</div>
</div>
<div id="scale-vs-mttf" class="section level2 hasAnchor" number="7.6">
<h2><span class="header-section-number">7.6</span> Scenario: Assessing the Impact of Changing the Scale Parameter of Component 3<a href="#scale-vs-mttf" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>By Equation , we see that MTTF<span class="math inline">\(_j\)</span> is proportional to the scale parameter <span class="math inline">\(\lambda_j\)</span>, which means
when we decrease the scale parameter of a component, we proportionally decrease the MTTF.
In this scenario, we start with the well-designed series system described in Table ,
and we will manipulate the MTTF of component 3, MTTF<span class="math inline">\(_3\)</span>, by changing its
scale parameter, <span class="math inline">\(\lambda_3\)</span>, and observing the effect this has on the MLE. Since the other components
had a similiar MTTF, we will arbitrarily choose component 1 to represent the other components.
The bottom plot shows the coverage probabilities for all parameters.</p>
<p>In Figure , we show the effect of changing the scale parameter of component <span class="math inline">\(3\)</span>, <span class="math inline">\(lambda_3\)</span>,
but map <span class="math inline">\(\lambda_3\)</span> to MTTF<span class="math inline">\(_3\)</span> to make it more intuitive to reason about. We vary the MTTF of component 3
from <span class="math inline">\(300\)</span> to <span class="math inline">\(1500\)</span> and the other components have their MTTFs fixed at around <span class="math inline">\(900\)</span>, as shown in
Table . We fix the masking probability to <span class="math inline">\(p = 0.215\)</span> (moderate masking),
the right-censoring quantile to <span class="math inline">\(q = 0.825\)</span> (moderate censoring), and the sample size to <span class="math inline">\(n = 100\)</span> (moderate sample size).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mttf-vs-ci"></span>
<embed src="image/5_system_mttf3_by_scale3.pdf" title="MTTF$_3$ vs MLE By Varying Scale" type="application/pdf" />
<p class="caption">
Figure 7.4: MTTF<span class="math inline">\(_3\)</span> vs MLE By Varying Scale
</p>
</div>
<div id="key-observations-3" class="section level3 hasAnchor" number="7.6.1">
<h3><span class="header-section-number">7.6.1</span> Key Observations<a href="#key-observations-3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="coverage-probability-cp-3" class="section level5 unnumbered hasAnchor" number="">
<h5>Coverage Probability (CP)<a href="#coverage-probability-cp-3" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>When MTTF of component 3 is much smaller than other components,
the CP for <span class="math inline">\(k_3\)</span> is very well calibrated (approximately obtaining the nominal level <span class="math inline">\(95\%\)</span>)
while the CP for other componentns are around <span class="math inline">\(90\%\)</span>, which is still reasonable.
(This is the case even though the width of the CI for <span class="math inline">\(k_3\)</span> is extremely narrow compared to the others).
As MTTF<span class="math inline">\(_3\)</span> increases, the CP for <span class="math inline">\(k_3\)</span> decreases, while the CP for the other components increase
slightly. The scale parameters are generally well-calibrated for all of the components, except
for component 3 when its MTTF is large and it dips down to <span class="math inline">\(90\%\)</span>. Despite the individual differences,
the mean of the CPs for shape and scale parameters hardly change.</p>
</div>
<div id="dispersion-of-mles-3" class="section level5 unnumbered hasAnchor" number="">
<h5>Dispersion of MLEs<a href="#dispersion-of-mles-3" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>For component 3, as its MTTF decreases, the dispersion of MLEs narrows,
indicating more precise estimates. Conversely, dispersion for other components widens. As MTTF
of component 3 increases, its dispersion widens while others narrow. This is consistent with
the fact that the smaller MTTF of component 3 means that, in this well-designed system at least,
it is more likely to be the component cause of failure, and so we have more information about
its parameters and are able to estimate them more accurately.</p>
</div>
<div id="iqr-of-bootstrapped-cis-3" class="section level5 unnumbered hasAnchor" number="">
<h5>IQR of Bootstrapped CIs<a href="#iqr-of-bootstrapped-cis-3" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The dark blue vertical lines representing IQR are consistent with the dispersion of MLEs,
which is the ideal behavior, and suggests that the BCa confidence intervals are performing well.</p>
</div>
<div id="bias-of-mles-2" class="section level5 unnumbered hasAnchor" number="">
<h5>Bias of MLEs<a href="#bias-of-mles-2" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>For component 3, the bias of MLE for the scale parameter becomes slightly more negatively biased
as MTTF<span class="math inline">\(_3\)</span> increases, and the bias of the MLE for the shape parameter becomes slightly more positively
biased. The MLE for the shape and scale parameters for component 1 have a very small bias, if any,
and are not affected by the MTTF<span class="math inline">\(_3\)</span>. The scale parameters are easier to estimate than the shape
parameters, and so they are less sensitive to changes in scale than the shape parameters, as
we will show in the next scenario.</p>
</div>
</div>
</div>
<div id="shape3-vary" class="section level2 hasAnchor" number="7.7">
<h2><span class="header-section-number">7.7</span> Scenario: Assessing the Impact of Changing the Shape Parameter of Component 3<a href="#shape3-vary" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The shape parameter determines the failure characteristics.
We vary the shape paramenter of component 3 from <span class="math inline">\(0.1\)</span> to <span class="math inline">\(3.5\)</span> and observe the effect
it has on the MLE.
When <span class="math inline">\(k_3 &lt; 1\)</span>, this indicates infant mortality, and when <span class="math inline">\(k_3 &gt; 1\)</span>, this indicates
wear-out failures.</p>
<p>We analyze the effect of component 3’s shape parameter on the MLE and the bootstrapped confidence intervals for the
shape and scale parameters of components 1 and 3 (the component we are varying). First, we look at the effect
on the scale parameter.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:prob3-vs-mle"></span>
<embed src="image/5_system_shape3_fig.pdf" title="Probability of Component 3 Failure vs MLE" width="100%" type="application/pdf" />
<p class="caption">
Figure 7.5: Probability of Component 3 Failure vs MLE
</p>
</div>
<div id="key-observations-4" class="section level3 hasAnchor" number="7.7.1">
<h3><span class="header-section-number">7.7.1</span> Key Observations<a href="#key-observations-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="coverage-probability-cp-4" class="section level5 unnumbered hasAnchor" number="">
<h5>Coverage Probability (CP)<a href="#coverage-probability-cp-4" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The CP for the scale parameters
are well-calibrated and close to the nominal level of <span class="math inline">\(0.95\)</span> for all values of <span class="math inline">\(\Pr\{K_i = 3\}\)</span>.
For the the shape parameter of component 3 (<span class="math inline">\(k_3\)</span>) in
bold orange colors, we see that it is well-calibrated for all values of
<span class="math inline">\(\Pr\{K_i = 3\}\)</span>, but actually may become too large for extreme values of <span class="math inline">\(\Pr\{K_i = 3\}\)</span>.
The CP for the shape parameters of the other components decreases with $<span class="math inline">\(\Pr\{K_i = 3\}\)</span>, dipping below <span class="math inline">\(90\%\)</span> for <span class="math inline">\(\Pr\{K_i = 3\} &gt; 0.4\)</span>. At a sample size of <span class="math inline">\(n = 100\)</span>, the CP for the shape parameters of the other components is generally not well-calibrated for <span class="math inline">\(\Pr\{K_i = 3\} &gt; 0.4\)</span>.</p>
</div>
<div id="dispersion-of-mles-4" class="section level5 unnumbered hasAnchor" number="">
<h5>Dispersion of MLEs<a href="#dispersion-of-mles-4" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The dispersion of the MLE for the shape and scale parameters of component 1, <span class="math inline">\(k_1\)</span> and <span class="math inline">\(\lambda_1\)</span>,
is fairly steady but begins to increase rapdily at the extreme values of <span class="math inline">\(\Pr\{K_i = 3\}\)</span>. This is indicative of
having less information about the failure characteristcs of component <span class="math inline">\(1\)</span> as component <span class="math inline">\(3\)</span> begins to dominate the
component cause of failure.
The dispersion of the shape parameter <span class="math inline">\(k_3\)</span> is initially quite large, indicative of having very little
information about the failure characteristcs of component 3 since it is unlikely to be the component cause of
failure, but its dispersion rapidly decreases as <span class="math inline">\(\Pr\{K_i = 3\}\)</span> increases and more information is
available about component 3’s failure characteristics. In fact, it nearly becomes a point at <span class="math inline">\(\Pr\{K_i = 3\} = 0.6\)</span>.
The dispersion of the the scale parameter of component <span class="math inline">\(3\)</span>, <span class="math inline">\(\lambda_1\)</span>, is quite steady and is less spread out
than the MLE for <span class="math inline">\(\lambda_1\)</span>, but at extreme values of <span class="math inline">\(\Pr\{K_i = 3\}\)</span>, it also begins to rapidly increase,
suggesting some complex interactions between the shape and scale parameters of component 3.</p>
</div>
<div id="iqr-of-bootstrapped-cis-4" class="section level5 unnumbered hasAnchor" number="">
<h5>IQR of Bootstrapped CIs<a href="#iqr-of-bootstrapped-cis-4" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The CIs precisely track the dispersion of the MLEs, which is the ideal behavior,
and suggests that the BCa confidence intervals are performing well.</p>
</div>
<div id="bias-of-mles-3" class="section level5 unnumbered hasAnchor" number="">
<h5>Bias of MLEs<a href="#bias-of-mles-3" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The MLE for the scale parameters are nearly unbiased and generally seem unaffected by changes
in <span class="math inline">\(\Pr\{K_i = 3\}\)</span>. As <span class="math inline">\(\Pr\{K_i = 3\}\)</span> increases the MLE is adjusting <span class="math inline">\(k_1\)</span> to be more
positively biased, decreasing its infant morality rate to make it less likely to be the
component cause of failure, and adjusting <span class="math inline">\(k_3\)</span> to be less positively biased, increasing
its infant mortality rate, to make it more likely to be the component cause of failure.</p>
</div>
</div>
</div>
</div>
<div id="future-work" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">8</span> Future Work<a href="#future-work" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="relaxation-of-masking-conditions" class="section level4 unnumbered hasAnchor" number="">
<h4>Relaxation of Masking Conditions<a href="#relaxation-of-masking-conditions" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Investigate relaxations of Conditions 1, 2, and 3.
Condition 1 stipulates that the failed component is always in
the candidate set,
<span class="math display">\[
    \Pr\{K_i \in \mathcal{C}_i\} = 1.
\]</span>
Instead, we could model this as a probability, where the probability
of the failed component being in the candidate set is a function
of the failure time <span class="math inline">\(T_i\)</span> and the component cause of failure <span class="math inline">\(K_i\)</span>,
<span class="math display">\[
    \Pr\{K_i \in \mathcal{C}_i | K_i = j, T_i = t_i\} = g(j, t_i).
\]</span>
Condition 2 stipulates that
<span class="math display">\[
    \Pr\{\mathcal{C}_i = c_i | T_i = t_i, K_i = j\} = 
    \Pr\{\mathcal{C}_i = c_i | T_i = t_i, K_i = j&#39;\}
\]</span>
for all <span class="math inline">\(j, j&#39; \in c_i\)</span>. We call this an <em>uninformed</em> candidate set,
since the conditional probability of the candidate set given the
failure time and component cause of failure is independent of the
component cause of failure. We could relax this condition to allow
for <em>informed</em> candidate sets, where the conditional probability
of the candidate set given the failure time and component cause of
failure is dependent on the component cause of failure.</p>
<p>In each of these violations or relaxations, we can either construct
a new likelihood model that takes this relaxation into account, or
we can use the existing likelihood model and assess the sensitivity
of the estimator to this violation. A potentially interesting way to
do the lattr is by using KL-divergence to measure the distance
between, for instance, the uninformed and informed candidate set models,
and then assess the sensitivity of the estimators to this distance.</p>
</div>
<div id="expanded-sensitivity-analyses" class="section level4 unnumbered hasAnchor" number="">
<h4>Expanded Sensitivity Analyses<a href="#expanded-sensitivity-analyses" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Explore the use of a reduced model that assumes homogeneity in shape parameters.
This approach would simplify the system to <span class="math inline">\(m+1\)</span> parameters, as opposed to the
<span class="math inline">\(2m\)</span> parameters in the current model, potentially increasing interpretability
and reducing estimator variability. This direction warrants detailed
investigation to ensure the reduced model retains sufficient accuracy and
adequately describes the data.</p>
</div>
<div id="semi-parametric-bootstrap" class="section level4 unnumbered hasAnchor" number="">
<h4>Semi-Parametric Bootstrap<a href="#semi-parametric-bootstrap" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We used the non-parameteric bootstrap to construct confidence intervals,
but we could also use the semi-parametric bootstrap.
In the semi-parametric bootstrap, instead of resampling from the original
data, we sample component lifetimes from the parametric distribution fitted
to the original data and sample candidate sets from the empirical distribution
of the conditional candidate sets in the original data.
This is a compromise between the non-parametric bootstrap and the fully
parametric bootstrap.[^30]
[^30]: The fully parametric bootstrap is not appropriate for our likelihood
model because we do not assume a parametric form for the distribution of the
candidate sets.</p>
</div>
<div id="data-augmentation" class="section level4 unnumbered hasAnchor" number="">
<h4>Data Augmentation<a href="#data-augmentation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Assess the robustness of Data Augmentation (DA) as an implicit
prior. For example, we may adopt the prior that the system is
well-designed and augment particularly small samples with synthetic
data from a reduced model (with homogenous shape parameters) fitted to the
original data.</p>
<p>Unlike a full Bayesian approach, where we would need to specify
a prior for the parameters, DA is an implicit prior that need not
be explicitly specified. It is a form of regularization that
reduces the variance of the estimator by leveraging the structure
of the model and the data.</p>
</div>
<div id="penalized-likelihood-for-homogenous-shape-parameters" class="section level4 unnumbered hasAnchor" number="">
<h4>Penalized Likelihood For Homogenous Shape Parameters<a href="#penalized-likelihood-for-homogenous-shape-parameters" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Assess the use of penalized likelihood methods instead of
DA as a form of regularization. For instance, we can add
a penalty term to the log-likelihood function that penalizes
the likelihood when the shape parameters are not close to
each other. Instead of using a reduced model, we can
use a penalized likelihood approach to encourage the shape
parameters to be close to each other, but not necessarily
equal.</p>
</div>
<div id="general-likelihood-model-with-predictors" class="section level4 unnumbered hasAnchor" number="">
<h4>General Likelihood Model with Predictors<a href="#general-likelihood-model-with-predictors" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In this paper, we focused on a likelihood model that assumed Weibull components
in a series configuration.
We can extend this model by generalizing the hazard functions in two ways:</p>
<ol style="list-style-type: decimal">
<li><p>Let the hazard model be a function of predictors <span class="math inline">\(\boldsymbol{w_1}, \ldots, \boldsymbol{w_n}\)</span>,
where <span class="math inline">\(\boldsymbol{w_i}\)</span> is a vector of predictors for the <span class="math inline">\(i\)</span>th observation. Then, the
hazard function for the <span class="math inline">\(j\)</span>th component is
<span class="math display">\[
 h_j(t_i|\boldsymbol{w_i};\boldsymbol{\beta_j}),
\]</span>
for instance we might make the shape and scale parameters of the Weibull
component model be a function of the predictors <span class="math inline">\(\boldsymbol{w_i}\)</span>.</p></li>
<li><p>Replace the Weibull hazard function with a more general hazard function.
For instance, in the Cox proportional hazards model <span class="citation">(Cox <a href="#ref-cox1972regression" role="doc-biblioref">1972</a>)</span>, the
hazard function for the <span class="math inline">\(j\)</span>th component is given by
<span class="math display">\[
 h_j(t_i|\boldsymbol{w_i};\boldsymbol{\beta_j}) = h_0(t_i) \exp(\boldsymbol{\beta_j}^T \boldsymbol{w_i}),
\]</span>
where <span class="math inline">\(h_{0}(t_i)\)</span> is a baseline hazard function shared by all components and
<span class="math inline">\(\boldsymbol{\beta_j}\)</span> is the parameter vector for the <span class="math inline">\(j\)</span>th component. A more general
model would allow the component hazard functions to take any valid form, namely
non-negative and integrable.</p></li>
</ol>
<p>In either case, by the relation
<span class="math display">\[
  R_j(t_i|\boldsymbol{w_i};\boldsymbol{\beta_j}) = e^{-H_j(t)},
\]</span>
where
<span class="math display">\[
  H_j(t_i) = \int_0^{t_i} h_j(u|\boldsymbol{w_i};\boldsymbol{\beta_j}) du
\]</span>
is the cumulative hazard function for the <span class="math inline">\(j\)</span> component, we
can plug these component hazard and reliability functions into the likelihood
contribution model in Theorem  to obtain a
general likelihood model with predictors for the series system.</p>
</div>
<div id="assess-the-calibration-of-other-related-bootstrapped-statistics" class="section level4 unnumbered hasAnchor" number="">
<h4>Assess the Calibration of Other Related Bootstrapped Statistics<a href="#assess-the-calibration-of-other-related-bootstrapped-statistics" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The calibration of the bootstrapped confidence intervals were evaluated
and shown to be quite robust. We could do a similar analysis for other
bootstrapped statistics. For instance, we could assess the bootstrapped <span class="math inline">\(95\%\)</span>
prediction interval for the probability that component <span class="math inline">\(j\)</span> is the component
cause of the next system failure given the data <span class="math inline">\(\mathcal{D}_n\)</span>,
<span class="math display">\[
    \Pr\{K_{n+1} = j | \mathcal{D}_n\}.
\]</span></p>
</div>
</div>
<div id="conclusion" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">9</span> Conclusion<a href="#conclusion" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This paper presented maximum likelihood methods for estimating
component reliability from masked failure data in series systems.
We accounted for right-censoring and masking issues in our likelihood model,
thereby achieving a rigorous framework for reliability analysis from limited
observational data.</p>
<p>Our simulation studies reveal that shape parameters are particularly sensitive
to data and harder to estimate precisely compared to scale parameters.
Right-censoring and masking were found to bias shape parameters positively,
although scale parameters exhibited more robust behavior. Despite these
challenges, bootstrapping techniques yielded well-calibrated confidence
intervals even for small sample sizes.</p>
<p>The sensitivities in shape parameters lead to a need for caution, especially
when dealing with small sample sizes. Coverage probabilities for shape
parameters, for instance, drop below <span class="math inline">\(90\%\)</span> in the presence of significant
masking. On the other hand, scale parameters display more robust properties,
maintaining well-calibrated confidence intervals even under challenging
conditions.</p>
<p>Overall, this work provides a rigorous framework for quantifying
component reliability from limited observational data. The methods
demonstrated accurate and robust performance despite the significant
challenges introduced by masking and right-censoring.</p>
<p>In light of our findings, to continue to refine our understanding and broaden
the applicability of these methods, future work can focus on relaxing modeling
assumptions, expanding the sensitivity analysis, and evaluating the viability
of methods designed to reduce the variability of shape parameter estimates.</p>
</div>



<div id="app-weibull-loglik-r" class="section level1 hasAnchor" number="10">
<h1><span class="header-section-number">A</span> Log-likelihood Function<a href="#app-weibull-loglik-r" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The following R code implements the log-likelihood function for the Weibull
series system with right censoring and masking of component failure data. It is
implemented in the R library <code>wei.series.md.c1.c2.c3</code> and
is available on <a href="https://github.com/queelius/wei.series.md.c1.c2.c3">GitHub</a>.
For clarity and brevity, we removed some of the functionality that is not
relevant to the analysis in this paper and produce a simplified version of the
code below.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a><span class="co">#&#39; Generates a log-likelihood function for a Weibull series system with respect</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a><span class="co">#&#39; to parameter `theta` (shape, scale) for masked data with candidate sets</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a><span class="co">#&#39; that satisfy conditions C1, C2, and C3 and right-censored data.</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true"></a><span class="co">#&#39;</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true"></a><span class="co">#&#39; @param df (masked) data frame</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true"></a><span class="co">#&#39; @param theta parameter vector (shape1, scale1, ..., shapem, scalem)</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true"></a><span class="co">#&#39; @returns Log-likelihood with respect to `theta` given `df`</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true"></a>loglik_wei_series_md_c1_c2_c3 &lt;-<span class="st"> </span><span class="cf">function</span>(df, theta) {</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true"></a>  n &lt;-<span class="st"> </span><span class="kw">nrow</span>(df)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true"></a>  C &lt;-<span class="st"> </span><span class="kw">md_decode_matrix</span>(df, candset)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true"></a>  m &lt;-<span class="st"> </span><span class="kw">ncol</span>(C)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true"></a>  delta &lt;-<span class="st"> </span>df[[right_censoring_indicator]]</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true"></a>  t &lt;-<span class="st"> </span>df[[lifetime]]</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true"></a>  k &lt;-<span class="st"> </span><span class="kw">length</span>(theta)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true"></a>  shapes &lt;-<span class="st"> </span>theta[<span class="kw">seq</span>(<span class="dv">1</span>, k, <span class="dv">2</span>)]</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true"></a>  scales &lt;-<span class="st"> </span>theta[<span class="kw">seq</span>(<span class="dv">2</span>, k, <span class="dv">2</span>)]</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true"></a>  s &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true"></a>    s &lt;-<span class="st"> </span>s <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>((t[i] <span class="op">/</span><span class="st"> </span>scales)<span class="op">^</span>shapes)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true"></a>    <span class="cf">if</span> (delta[i]) {</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true"></a>      s &lt;-<span class="st"> </span>s <span class="op">+</span><span class="st"> </span><span class="kw">log</span>(<span class="kw">sum</span>(shapes[C[i, ]] <span class="op">/</span><span class="st"> </span>scales[C[i, ]] <span class="op">*</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true"></a><span class="st">        </span>(t[i] <span class="op">/</span><span class="st"> </span>scales[C[i, ]])<span class="op">^</span>(shapes[C[i, ]] <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)))</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true"></a>    }</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true"></a>  }</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true"></a>  <span class="kw">return</span>(s)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true"></a>}</span></code></pre></div>
</div>
<div id="app-score-fn-r" class="section level1 hasAnchor" number="11">
<h1><span class="header-section-number">B</span> Score Function<a href="#app-score-fn-r" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The following code is the score function (gradient of the log-likelihood
function with respect to <span class="math inline">\(\boldsymbol{\theta}\)</span>) for the Weibull series system with a
likelihood model that includes masked component cause of failure and
right-censoring. It is implemented in the R library <code>wei.series.md.c1.c2.c3</code> and
is available on <a href="https://github.com/queelius/wei.series.md.c1.c2.c3">GitHub</a>.</p>
<p>For clarity and brevity, we removed some of the functionality that is not
relevant to the
analysis in this paper.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="co">#&#39; Computes the score function (gradient of the log-likelihood function) for a</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a><span class="co">#&#39; Weibull series system with respect to parameter `theta` (shape, scale) for masked</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a><span class="co">#&#39; data with candidate sets that satisfy conditions C1, C2, and C3 and right-censored</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true"></a><span class="co">#&#39; data.</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true"></a><span class="co">#&#39;</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true"></a><span class="co">#&#39; @param df (masked) data frame</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true"></a><span class="co">#&#39; @param theta parameter vector (shape1, scale1, ..., shapem, scalem)</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true"></a><span class="co">#&#39; @returns Score with respect to `theta` given `df`</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true"></a>score_wei_series_md_c1_c2_c3 &lt;-<span class="st"> </span><span class="cf">function</span>(df, theta) {</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true"></a>  n &lt;-<span class="st"> </span><span class="kw">nrow</span>(df)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true"></a>  C &lt;-<span class="st"> </span><span class="kw">md_decode_matrix</span>(df, candset)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true"></a>  m &lt;-<span class="st"> </span><span class="kw">ncol</span>(C)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true"></a>  delta &lt;-<span class="st"> </span>df[[right_censoring_indicator]]</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true"></a>  t &lt;-<span class="st"> </span>df[[lifetime]]</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true"></a>  shapes &lt;-<span class="st"> </span>theta[<span class="kw">seq</span>(<span class="dv">1</span>, <span class="kw">length</span>(theta), <span class="dv">2</span>)]</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true"></a>  scales &lt;-<span class="st"> </span>theta[<span class="kw">seq</span>(<span class="dv">2</span>, <span class="kw">length</span>(theta), <span class="dv">2</span>)]</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true"></a>  shape_scores &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, m)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true"></a>  scale_scores &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, m)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true"></a>    rt.term.shapes &lt;-<span class="st"> </span><span class="op">-</span>(t[i] <span class="op">/</span><span class="st"> </span>scales)<span class="op">^</span>shapes <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(t[i] <span class="op">/</span><span class="st"> </span>scales)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true"></a>    rt.term.scales &lt;-<span class="st"> </span>(shapes <span class="op">/</span><span class="st"> </span>scales) <span class="op">*</span><span class="st"> </span>(t[i] <span class="op">/</span><span class="st"> </span>scales)<span class="op">^</span>shapes</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true"></a>    <span class="co"># Initialize mask terms to 0</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true"></a>    mask.term.shapes &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, m)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true"></a>    mask.term.scales &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, m)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true"></a>    <span class="cf">if</span> (delta[i]) {</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true"></a>      cindex &lt;-<span class="st"> </span>C[i, ]</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true"></a>      denom &lt;-<span class="st"> </span><span class="kw">sum</span>(shapes[cindex] <span class="op">/</span><span class="st"> </span>scales[cindex] <span class="op">*</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true"></a><span class="st">        </span>(t[i] <span class="op">/</span><span class="st"> </span>scales[cindex])<span class="op">^</span>(shapes[cindex] <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true"></a></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true"></a>      numer.shapes &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span>t[i] <span class="op">*</span><span class="st"> </span>(t[i] <span class="op">/</span><span class="st"> </span>scales[cindex])<span class="op">^</span>shapes[cindex] <span class="op">*</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true"></a><span class="st">        </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>shapes[cindex] <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(t[i] <span class="op">/</span><span class="st"> </span>scales[cindex]))</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true"></a>      mask.term.shapes[cindex] &lt;-<span class="st"> </span>numer.shapes <span class="op">/</span><span class="st"> </span>denom</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true"></a></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true"></a>      numer.scales &lt;-<span class="st"> </span>(shapes[cindex] <span class="op">/</span><span class="st"> </span>scales[cindex])<span class="op">^</span><span class="dv">2</span> <span class="op">*</span></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true"></a><span class="st">        </span>(t[i] <span class="op">/</span><span class="st"> </span>scales[cindex])<span class="op">^</span>(shapes[cindex] <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true"></a>      mask.term.scales[cindex] &lt;-<span class="st"> </span>numer.scales <span class="op">/</span><span class="st"> </span>denom</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true"></a>    }</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true"></a></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true"></a>    shape_scores &lt;-<span class="st"> </span>shape_scores <span class="op">+</span><span class="st"> </span>rt.term.shapes <span class="op">+</span><span class="st"> </span>mask.term.shapes</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true"></a>    scale_scores &lt;-<span class="st"> </span>scale_scores <span class="op">+</span><span class="st"> </span>rt.term.scales <span class="op">-</span><span class="st"> </span>mask.term.scales</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true"></a>  }</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true"></a></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true"></a>  scr &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">length</span>(theta))</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true"></a>  scr[<span class="kw">seq</span>(<span class="dv">1</span>, <span class="kw">length</span>(theta), <span class="dv">2</span>)] &lt;-<span class="st"> </span>shape_scores</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true"></a>  scr[<span class="kw">seq</span>(<span class="dv">2</span>, <span class="kw">length</span>(theta), <span class="dv">2</span>)] &lt;-<span class="st"> </span>scale_scores</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true"></a>  <span class="kw">return</span>(scr)</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true"></a>}</span></code></pre></div>
</div>
<div id="app-sim-study-r" class="section level1 hasAnchor" number="12">
<h1><span class="header-section-number">C</span> Scenario Simulation<a href="#app-sim-study-r" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The following R code is the Monte-carlo simulation code for running the various
scenarios described in Section <a href="#sim-study">7</a>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a><span class="co">#### Setup simulation parameters here ####</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a>theta &lt;-<span class="st"> </span><span class="kw">c</span>(</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true"></a>  <span class="dt">shape1 =</span> <span class="fl">1.2576</span>, <span class="dt">scale1 =</span> <span class="fl">994.3661</span>,</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true"></a>  <span class="dt">shape2 =</span> <span class="fl">1.1635</span>, <span class="dt">scale2 =</span> <span class="fl">908.9458</span>,</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true"></a>  <span class="dt">shape3 =</span> <span class="ot">NA</span>, <span class="dt">scale3 =</span> <span class="fl">840.1141</span>,</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true"></a>  <span class="dt">shape4 =</span> <span class="fl">1.1802</span>, <span class="dt">scale4 =</span> <span class="fl">940.1342</span>,</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true"></a>  <span class="dt">shape5 =</span> <span class="fl">1.2034</span>, <span class="dt">scale5 =</span> <span class="fl">923.1631</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true"></a>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true"></a>shapes3 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">1.1308</span>) <span class="co"># shape 3 true parameter values to simulate</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true"></a>scales3 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">840.1141</span>) <span class="co"># scale 3 true parameter values to simulate</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true"></a>N &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">30</span>, <span class="dv">60</span>, <span class="dv">100</span>) <span class="co"># sample sizes to simulate</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true"></a>P &lt;-<span class="st"> </span><span class="kw">c</span>(.<span class="dv">215</span>) <span class="co"># masking probabilities to simulate</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true"></a>Q &lt;-<span class="st"> </span><span class="kw">c</span>(.<span class="dv">825</span>) <span class="co"># right censoring probabilities to simulate</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true"></a>R &lt;-<span class="st"> </span>1000L <span class="co"># number of simulations per scenario</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true"></a>B &lt;-<span class="st"> </span>1000L <span class="co"># number of bootstrap samples</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true"></a>max_iter &lt;-<span class="st"> </span>125L <span class="co"># max iterations for MLE</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true"></a>max_boot_iter &lt;-<span class="st"> </span>125L <span class="co"># max iterations for bootstrap MLE</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true"></a>n_cores &lt;-<span class="st"> </span><span class="kw">detectCores</span>() <span class="op">-</span><span class="st"> </span><span class="dv">1</span> <span class="co"># number of cores to use for parallel processing</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true"></a>filename &lt;-<span class="st"> &quot;data&quot;</span> <span class="co"># filename prefix for output files</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true"></a><span class="co">#### Simulation code below here ####</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true"></a><span class="kw">library</span>(parallel)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true"></a><span class="kw">library</span>(boot)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true"></a><span class="kw">library</span>(algebraic.mle) <span class="co"># for `mle_boot`</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true"></a><span class="kw">library</span>(wei.series.md.c1.c2.c3) <span class="co"># for `mle_lbfgsb_wei_series_md_c1_c2_c3` etc</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true"></a></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true"></a>file.meta &lt;-<span class="st"> </span><span class="kw">paste0</span>(filename, <span class="st">&quot;.txt&quot;</span>)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true"></a>file.csv &lt;-<span class="st"> </span><span class="kw">paste0</span>(filename, <span class="st">&quot;.csv&quot;</span>)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true"></a><span class="cf">if</span> (<span class="kw">file.exists</span>(file.meta)) {</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true"></a>  <span class="kw">stop</span>(<span class="st">&quot;File already exists: &quot;</span>, file.meta)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true"></a>}</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true"></a><span class="cf">if</span> (<span class="kw">file.exists</span>(file.csv)) {</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true"></a>  <span class="kw">stop</span>(<span class="st">&quot;File already exists: &quot;</span>, file.csv)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true"></a>}</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true"></a></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true"></a>shapes &lt;-<span class="st"> </span>theta[<span class="kw">seq</span>(<span class="dv">1</span>, <span class="kw">length</span>(theta), <span class="dv">2</span>)]</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true"></a>scales &lt;-<span class="st"> </span>theta[<span class="kw">seq</span>(<span class="dv">2</span>, <span class="kw">length</span>(theta), <span class="dv">2</span>)]</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true"></a>m &lt;-<span class="st"> </span><span class="kw">length</span>(shapes)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true"></a></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true"></a><span class="kw">sink</span>(file.meta)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;boostrap of confidence intervals:</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;   simulated on: &quot;</span>, <span class="kw">Sys.time</span>(), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;   type: &quot;</span>, ci_method, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;weibull series system:</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;   number of components: &quot;</span>, m, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;   scale parameters: &quot;</span>, scales, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;   shape parameters: &quot;</span>, shapes, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;simulation parameters:</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;   shapes3: &quot;</span>, shapes3, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;   scales3: &quot;</span>, scales3, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;   N: &quot;</span>, N, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;   P: &quot;</span>, P, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;   Q: &quot;</span>, Q, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;   R: &quot;</span>, R, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;   B: &quot;</span>, B, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;   max_iter: &quot;</span>, max_iter, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;   max_boot_iter: &quot;</span>, max_boot_iter, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true"></a><span class="kw">cat</span>(<span class="st">&quot;   n_cores: &quot;</span>, n_cores, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true"></a><span class="kw">sink</span>()</span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true"></a></span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true"></a><span class="cf">for</span> (scale3 <span class="cf">in</span> scales3) {</span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true"></a>  <span class="cf">for</span> (shape3 <span class="cf">in</span> shapes3) {</span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true"></a>    <span class="cf">for</span> (n <span class="cf">in</span> N) {</span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true"></a>      <span class="cf">for</span> (p <span class="cf">in</span> P) {</span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true"></a>        <span class="cf">for</span> (q <span class="cf">in</span> Q) {</span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true"></a>          shapes[<span class="dv">3</span>] &lt;-<span class="st"> </span>shape3</span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true"></a>          theta[<span class="st">&quot;shape3&quot;</span>] &lt;-<span class="st"> </span>shape3</span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true"></a></span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true"></a>          <span class="kw">cat</span>(<span class="st">&quot;[starting scenario: scale3 = &quot;</span>, scale3, <span class="st">&quot;, shape3 = &quot;</span>, shape3,</span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true"></a>            <span class="st">&quot;, n = &quot;</span>, n, <span class="st">&quot;, p = &quot;</span>, p, <span class="st">&quot;, q = &quot;</span>, q, <span class="st">&quot;]</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true"></a>          tau &lt;-<span class="st"> </span><span class="kw">qwei_series</span>(<span class="dt">p =</span> q, <span class="dt">scales =</span> scales, <span class="dt">shapes =</span> shapes)</span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true"></a></span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true"></a>          <span class="co"># we compute R MLEs for each scenario</span></span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true"></a>          shapes.mle &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow =</span> R, <span class="dt">ncol =</span> m)</span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true"></a>          scales.mle &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow =</span> R, <span class="dt">ncol =</span> m)</span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true"></a>          shapes.lower &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow =</span> R, <span class="dt">ncol =</span> m)</span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true"></a>          shapes.upper &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow =</span> R, <span class="dt">ncol =</span> m)</span>
<span id="cb3-80"><a href="#cb3-80" aria-hidden="true"></a>          scales.lower &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow =</span> R, <span class="dt">ncol =</span> m)</span>
<span id="cb3-81"><a href="#cb3-81" aria-hidden="true"></a>          scales.upper &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow =</span> R, <span class="dt">ncol =</span> m)</span>
<span id="cb3-82"><a href="#cb3-82" aria-hidden="true"></a></span>
<span id="cb3-83"><a href="#cb3-83" aria-hidden="true"></a>          iter &lt;-<span class="st"> </span>0L</span>
<span id="cb3-84"><a href="#cb3-84" aria-hidden="true"></a>          <span class="cf">repeat</span> {</span>
<span id="cb3-85"><a href="#cb3-85" aria-hidden="true"></a>            retry &lt;-<span class="st"> </span><span class="ot">FALSE</span></span>
<span id="cb3-86"><a href="#cb3-86" aria-hidden="true"></a>            <span class="kw">tryCatch</span>(</span>
<span id="cb3-87"><a href="#cb3-87" aria-hidden="true"></a>              {</span>
<span id="cb3-88"><a href="#cb3-88" aria-hidden="true"></a>                <span class="cf">repeat</span> {</span>
<span id="cb3-89"><a href="#cb3-89" aria-hidden="true"></a>                  df &lt;-<span class="st"> </span><span class="kw">generate_guo_weibull_table_2_data</span>(</span>
<span id="cb3-90"><a href="#cb3-90" aria-hidden="true"></a>                    <span class="dt">shapes =</span> shapes, <span class="dt">scales =</span> scales, <span class="dt">n =</span> n, <span class="dt">p =</span> p, <span class="dt">tau =</span> tau</span>
<span id="cb3-91"><a href="#cb3-91" aria-hidden="true"></a>                  )</span>
<span id="cb3-92"><a href="#cb3-92" aria-hidden="true"></a></span>
<span id="cb3-93"><a href="#cb3-93" aria-hidden="true"></a>                  sol &lt;-<span class="st"> </span><span class="kw">mle_lbfgsb_wei_series_md_c1_c2_c3</span>(</span>
<span id="cb3-94"><a href="#cb3-94" aria-hidden="true"></a>                    <span class="dt">theta0 =</span> theta, <span class="dt">df =</span> df, <span class="dt">hessian =</span> <span class="ot">FALSE</span>,</span>
<span id="cb3-95"><a href="#cb3-95" aria-hidden="true"></a>                    <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">maxit =</span> max_iter, <span class="dt">parscale =</span> theta)</span>
<span id="cb3-96"><a href="#cb3-96" aria-hidden="true"></a>                  )</span>
<span id="cb3-97"><a href="#cb3-97" aria-hidden="true"></a>                  <span class="cf">if</span> (sol<span class="op">$</span>convergence <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) {</span>
<span id="cb3-98"><a href="#cb3-98" aria-hidden="true"></a>                    <span class="cf">break</span></span>
<span id="cb3-99"><a href="#cb3-99" aria-hidden="true"></a>                  }</span>
<span id="cb3-100"><a href="#cb3-100" aria-hidden="true"></a>                  <span class="kw">cat</span>(<span class="st">&quot;[&quot;</span>, iter, <span class="st">&quot;] MLE did not converge, retrying.</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-101"><a href="#cb3-101" aria-hidden="true"></a>                }</span>
<span id="cb3-102"><a href="#cb3-102" aria-hidden="true"></a></span>
<span id="cb3-103"><a href="#cb3-103" aria-hidden="true"></a>                mle_solver &lt;-<span class="st"> </span><span class="cf">function</span>(df, i) {</span>
<span id="cb3-104"><a href="#cb3-104" aria-hidden="true"></a>                  <span class="kw">mle_lbfgsb_wei_series_md_c1_c2_c3</span>(</span>
<span id="cb3-105"><a href="#cb3-105" aria-hidden="true"></a>                    <span class="dt">theta0 =</span> sol<span class="op">$</span>par, <span class="dt">df =</span> df[i, ], <span class="dt">hessian =</span> <span class="ot">FALSE</span>,</span>
<span id="cb3-106"><a href="#cb3-106" aria-hidden="true"></a>                    <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">maxit =</span> max_boot_iter, <span class="dt">parscale =</span> sol<span class="op">$</span>par)</span>
<span id="cb3-107"><a href="#cb3-107" aria-hidden="true"></a>                  )<span class="op">$</span>par</span>
<span id="cb3-108"><a href="#cb3-108" aria-hidden="true"></a>                }</span>
<span id="cb3-109"><a href="#cb3-109" aria-hidden="true"></a></span>
<span id="cb3-110"><a href="#cb3-110" aria-hidden="true"></a>                <span class="co"># do the non-parametric bootstrap</span></span>
<span id="cb3-111"><a href="#cb3-111" aria-hidden="true"></a>                sol.boot &lt;-<span class="st"> </span><span class="kw">boot</span>(df, mle_solver, <span class="dt">R =</span> B, <span class="dt">parallel =</span> <span class="st">&quot;multicore&quot;</span>,</span>
<span id="cb3-112"><a href="#cb3-112" aria-hidden="true"></a>                  <span class="dt">ncpus =</span> n_cores)</span>
<span id="cb3-113"><a href="#cb3-113" aria-hidden="true"></a>              },</span>
<span id="cb3-114"><a href="#cb3-114" aria-hidden="true"></a>              <span class="dt">error =</span> <span class="cf">function</span>(e) {</span>
<span id="cb3-115"><a href="#cb3-115" aria-hidden="true"></a>                <span class="kw">cat</span>(<span class="st">&quot;[error] &quot;</span>, <span class="kw">conditionMessage</span>(e), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-116"><a href="#cb3-116" aria-hidden="true"></a>                <span class="kw">cat</span>(<span class="st">&quot;[retrying scenario: n = &quot;</span>, n, <span class="st">&quot;, p = &quot;</span>, p, <span class="st">&quot;, q = &quot;</span>, q, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-117"><a href="#cb3-117" aria-hidden="true"></a>                retry &lt;&lt;-<span class="st"> </span><span class="ot">TRUE</span></span>
<span id="cb3-118"><a href="#cb3-118" aria-hidden="true"></a>              }</span>
<span id="cb3-119"><a href="#cb3-119" aria-hidden="true"></a>            )</span>
<span id="cb3-120"><a href="#cb3-120" aria-hidden="true"></a>            <span class="cf">if</span> (retry) {</span>
<span id="cb3-121"><a href="#cb3-121" aria-hidden="true"></a>              <span class="cf">next</span></span>
<span id="cb3-122"><a href="#cb3-122" aria-hidden="true"></a>            }</span>
<span id="cb3-123"><a href="#cb3-123" aria-hidden="true"></a>            iter &lt;-<span class="st"> </span>iter <span class="op">+</span><span class="st"> </span>1L</span>
<span id="cb3-124"><a href="#cb3-124" aria-hidden="true"></a>            shapes.mle[iter, ] &lt;-<span class="st"> </span>sol<span class="op">$</span>par[<span class="kw">seq</span>(<span class="dv">1</span>, <span class="kw">length</span>(theta), <span class="dv">2</span>)]</span>
<span id="cb3-125"><a href="#cb3-125" aria-hidden="true"></a>            scales.mle[iter, ] &lt;-<span class="st"> </span>sol<span class="op">$</span>par[<span class="kw">seq</span>(<span class="dv">2</span>, <span class="kw">length</span>(theta), <span class="dv">2</span>)]</span>
<span id="cb3-126"><a href="#cb3-126" aria-hidden="true"></a></span>
<span id="cb3-127"><a href="#cb3-127" aria-hidden="true"></a>            <span class="kw">tryCatch</span>(</span>
<span id="cb3-128"><a href="#cb3-128" aria-hidden="true"></a>              {</span>
<span id="cb3-129"><a href="#cb3-129" aria-hidden="true"></a>                ci &lt;-<span class="st"> </span><span class="kw">confint</span>(<span class="kw">mle_boot</span>(sol.boot), <span class="dt">type =</span> ci_method,</span>
<span id="cb3-130"><a href="#cb3-130" aria-hidden="true"></a>                    <span class="dt">level =</span> ci_level)</span>
<span id="cb3-131"><a href="#cb3-131" aria-hidden="true"></a>                shapes.ci &lt;-<span class="st"> </span>ci[<span class="kw">seq</span>(<span class="dv">1</span>, <span class="kw">length</span>(theta), <span class="dv">2</span>), ]</span>
<span id="cb3-132"><a href="#cb3-132" aria-hidden="true"></a>                scales.ci &lt;-<span class="st"> </span>ci[<span class="kw">seq</span>(<span class="dv">2</span>, <span class="kw">length</span>(theta), <span class="dv">2</span>), ]</span>
<span id="cb3-133"><a href="#cb3-133" aria-hidden="true"></a>                shapes.lower[iter, ] &lt;-<span class="st"> </span>shapes.ci[, <span class="dv">1</span>]</span>
<span id="cb3-134"><a href="#cb3-134" aria-hidden="true"></a>                shapes.upper[iter, ] &lt;-<span class="st"> </span>shapes.ci[, <span class="dv">2</span>]</span>
<span id="cb3-135"><a href="#cb3-135" aria-hidden="true"></a>                scales.lower[iter, ] &lt;-<span class="st"> </span>scales.ci[, <span class="dv">1</span>]</span>
<span id="cb3-136"><a href="#cb3-136" aria-hidden="true"></a>                scales.upper[iter, ] &lt;-<span class="st"> </span>scales.ci[, <span class="dv">2</span>]</span>
<span id="cb3-137"><a href="#cb3-137" aria-hidden="true"></a>              },</span>
<span id="cb3-138"><a href="#cb3-138" aria-hidden="true"></a>              <span class="dt">error =</span> <span class="cf">function</span>(e) {</span>
<span id="cb3-139"><a href="#cb3-139" aria-hidden="true"></a>                <span class="kw">cat</span>(<span class="st">&quot;[error] &quot;</span>, <span class="kw">conditionMessage</span>(e), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-140"><a href="#cb3-140" aria-hidden="true"></a>              }</span>
<span id="cb3-141"><a href="#cb3-141" aria-hidden="true"></a>            )</span>
<span id="cb3-142"><a href="#cb3-142" aria-hidden="true"></a>            <span class="cf">if</span> (iter <span class="op">%%</span><span class="st"> </span><span class="dv">5</span> <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) {</span>
<span id="cb3-143"><a href="#cb3-143" aria-hidden="true"></a>              <span class="kw">cat</span>(<span class="st">&quot;[iteration &quot;</span>, iter, <span class="st">&quot;] shapes = &quot;</span>, shapes.mle[iter, ],</span>
<span id="cb3-144"><a href="#cb3-144" aria-hidden="true"></a>                  <span class="st">&quot;scales = &quot;</span>, scales.mle[iter, ], <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb3-145"><a href="#cb3-145" aria-hidden="true"></a>            }</span>
<span id="cb3-146"><a href="#cb3-146" aria-hidden="true"></a></span>
<span id="cb3-147"><a href="#cb3-147" aria-hidden="true"></a>            <span class="cf">if</span> (iter <span class="op">==</span><span class="st"> </span>R) {</span>
<span id="cb3-148"><a href="#cb3-148" aria-hidden="true"></a>              <span class="cf">break</span></span>
<span id="cb3-149"><a href="#cb3-149" aria-hidden="true"></a>            }</span>
<span id="cb3-150"><a href="#cb3-150" aria-hidden="true"></a>          }</span>
<span id="cb3-151"><a href="#cb3-151" aria-hidden="true"></a></span>
<span id="cb3-152"><a href="#cb3-152" aria-hidden="true"></a>          df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb3-153"><a href="#cb3-153" aria-hidden="true"></a>            <span class="dt">n =</span> <span class="kw">rep</span>(n, R), <span class="kw">rep</span>(scale3, R), <span class="kw">rep</span>(shape3, R),</span>
<span id="cb3-154"><a href="#cb3-154" aria-hidden="true"></a>            <span class="dt">p =</span> <span class="kw">rep</span>(p, R), <span class="dt">q =</span> <span class="kw">rep</span>(q, R), <span class="dt">tau =</span> <span class="kw">rep</span>(tau, R), <span class="dt">B =</span> <span class="kw">rep</span>(B, R),</span>
<span id="cb3-155"><a href="#cb3-155" aria-hidden="true"></a>            <span class="dt">shapes =</span> shapes.mle, <span class="dt">scales =</span> scales.mle,</span>
<span id="cb3-156"><a href="#cb3-156" aria-hidden="true"></a>            <span class="dt">shapes.lower =</span> shapes.lower, <span class="dt">shapes.upper =</span> shapes.upper,</span>
<span id="cb3-157"><a href="#cb3-157" aria-hidden="true"></a>            <span class="dt">scales.lower =</span> scales.lower, <span class="dt">scales.upper =</span> scales.upper</span>
<span id="cb3-158"><a href="#cb3-158" aria-hidden="true"></a>          )</span>
<span id="cb3-159"><a href="#cb3-159" aria-hidden="true"></a></span>
<span id="cb3-160"><a href="#cb3-160" aria-hidden="true"></a>          <span class="kw">write.table</span>(df,</span>
<span id="cb3-161"><a href="#cb3-161" aria-hidden="true"></a>            <span class="dt">file =</span> file.csv, <span class="dt">sep =</span> <span class="st">&quot;,&quot;</span>, <span class="dt">row.names =</span> <span class="ot">FALSE</span>,</span>
<span id="cb3-162"><a href="#cb3-162" aria-hidden="true"></a>            <span class="dt">col.names =</span> <span class="op">!</span><span class="kw">file.exists</span>(file.csv), <span class="dt">append =</span> <span class="ot">TRUE</span></span>
<span id="cb3-163"><a href="#cb3-163" aria-hidden="true"></a>          )</span>
<span id="cb3-164"><a href="#cb3-164" aria-hidden="true"></a>        }</span>
<span id="cb3-165"><a href="#cb3-165" aria-hidden="true"></a>      }</span>
<span id="cb3-166"><a href="#cb3-166" aria-hidden="true"></a>    }</span>
<span id="cb3-167"><a href="#cb3-167" aria-hidden="true"></a>  }</span>
<span id="cb3-168"><a href="#cb3-168" aria-hidden="true"></a>}</span></code></pre></div>
</div>
<div id="app-cand-model-r" class="section level1 hasAnchor" number="13">
<h1><span class="header-section-number">D</span> Bernoulli Candidate Set Model<a href="#app-cand-model-r" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a><span class="co">#&#39; Bernoulli candidate set model is a particular type of *uninformed* model.</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a><span class="co">#&#39; This model satisfies conditions C1, C2, and C3.</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true"></a><span class="co">#&#39; The failed component will be in the corresponding candidate set with</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true"></a><span class="co">#&#39; probability 1, and the remaining components will be in the candidate set</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true"></a><span class="co">#&#39; with probability `p` (the same probability for each component). `p`</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true"></a><span class="co">#&#39; may be different for each system, but it is assumed to be the same for</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true"></a><span class="co">#&#39; each component within a system, so `p` can be a vector such that the</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true"></a><span class="co">#&#39; length of `p` is the number of systems in the data set (with recycling</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true"></a><span class="co">#&#39; if necessary).</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true"></a><span class="co">#&#39;</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true"></a><span class="co">#&#39; @param df masked data.</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true"></a><span class="co">#&#39; @param p a vector of probabilities (p[j] is the probability that the jth</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true"></a><span class="co">#&#39;          system will include a non-failed component in its candidate set,</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true"></a><span class="co">#&#39;          assuming the jth system is not right-censored).</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true"></a>md_bernoulli_cand_c1_c2_c3 &lt;-<span class="st"> </span><span class="cf">function</span>(df, p) {</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true"></a>  n &lt;-<span class="st"> </span><span class="kw">nrow</span>(df)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true"></a>  p &lt;-<span class="st"> </span><span class="kw">rep</span>(p, <span class="dt">length.out =</span> n)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true"></a>  Tm &lt;-<span class="st"> </span><span class="kw">md_decode_matrix</span>(df, comp)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true"></a>  m &lt;-<span class="st"> </span><span class="kw">ncol</span>(Tm)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true"></a>  Q &lt;-<span class="st"> </span><span class="kw">matrix</span>(p, <span class="dt">nrow =</span> n, <span class="dt">ncol =</span> m)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true"></a>  Q[<span class="kw">cbind</span>(<span class="dv">1</span><span class="op">:</span>n, <span class="kw">apply</span>(Tm, <span class="dv">1</span>, which.min))] &lt;-<span class="st"> </span><span class="dv">1</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true"></a>  Q[<span class="op">!</span>df[[right_censoring_indicator]], ] &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true"></a>  df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">md_encode_matrix</span>(Q, prob))</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true"></a>}</span></code></pre></div>
</div>
<div id="app-series-quantile" class="section level1 hasAnchor" number="14">
<h1><span class="header-section-number">E</span> Series System Quantile Function<a href="#app-series-quantile" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a><span class="co">#&#39; Quantile function (inverse of the cdf).</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true"></a><span class="co">#&#39; By definition, the quantile `p` * 100% for a strictly monotonically increasing</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true"></a><span class="co">#&#39; cdf `F` is the value `t` that satisfies `F(t) - p = 0`.</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true"></a><span class="co">#&#39; We solve for `t` using newton&#39;s method.</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true"></a><span class="co">#&#39;</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true"></a><span class="co">#&#39; @param p vector of probabilities.</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true"></a><span class="co">#&#39; @param shapes vector of weibull shape parameters for weibull lifetime</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true"></a><span class="co">#&#39;               components</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true"></a><span class="co">#&#39; @param scales vector of weibull scale parameters for weibull lifetime</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true"></a><span class="co">#&#39;               components</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true"></a>qwei_series &lt;-<span class="st"> </span><span class="cf">function</span>(p, shapes, scales) {</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true"></a>  t0 &lt;-<span class="st"> </span><span class="dv">1</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true"></a>  <span class="cf">repeat</span> {</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true"></a>    t1 &lt;-<span class="st"> </span>t0 <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>((t0 <span class="op">/</span><span class="st"> </span>scales)<span class="op">^</span>shapes) <span class="op">+</span><span class="st"> </span><span class="kw">log</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p) <span class="op">/</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true"></a><span class="st">      </span><span class="kw">sum</span>(shapes <span class="op">*</span><span class="st"> </span>t0<span class="op">^</span>(shapes <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>scales<span class="op">^</span>shapes)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true"></a>    <span class="cf">if</span> (<span class="kw">abs</span>(t1 <span class="op">-</span><span class="st"> </span>t0) <span class="op">&lt;</span><span class="st"> </span>tol) {</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true"></a>      <span class="cf">break</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true"></a>    }</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true"></a>    t0 &lt;-<span class="st"> </span>t1</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true"></a>  }</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true"></a>  <span class="kw">return</span>(t1)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true"></a>}</span></code></pre></div>

<div id="introduction-1" class="section level2 hasAnchor" number="14.1">
<h2><span class="header-section-number">E.1</span> Introduction<a href="#introduction-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Estimating reliability of individual components from system-level data is challenging</li>
<li>Failure times and causes often unobserved</li>
<li>Developed likelihood framework to leverage observational data</li>
<li>Simulation studies assess accuracy under small samples and significant masking</li>
</ul>
</div>
<div id="series-system-model" class="section level2 hasAnchor" number="14.2">
<h2><span class="header-section-number">E.2</span> Series System Model<a href="#series-system-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Components in series configuration</li>
<li>Lifetimes iid Weibull</li>
<li>Derived system:
<ul>
<li>Reliability function: Product of components</li>
<li>Probability density: Function of component densities</li>
<li>Hazard function: Sum of component hazards</li>
</ul></li>
</ul>
</div>
<div id="likelihood-model" class="section level2 hasAnchor" number="14.3">
<h2><span class="header-section-number">E.3</span> Likelihood Model<a href="#likelihood-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Right censoring: Unobserved lifetimes</li>
<li>Masked causes: Candidate sets</li>
<li>Assumptions on candidate sets:
<ul>
<li>Condition 1: Contains failed component</li>
<li>Condition 2: Equal failure probability within candidate set</li>
<li>Condition 3: Independent of parameters</li>
</ul></li>
<li>Likelihood contributions:
<ul>
<li>Right censoring: System reliability <span class="math inline">\(\prod_j R_j(t;\boldsymbol{\theta_j})\)</span></li>
<li>Masked causes: <span class="math inline">\(\prod_l R_l(t;\boldsymbol{\theta_j}) \sum_j h_j(t;\boldsymbol{\theta_j})\)</span></li>
</ul></li>
</ul>
</div>
<div id="estimation-methodology" class="section level2 hasAnchor" number="14.4">
<h2><span class="header-section-number">E.4</span> Estimation Methodology<a href="#estimation-methodology" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Maximum Likelihood Estimation
<ul>
<li>Asymptotic normality and efficiency</li>
<li>Small sample issues</li>
</ul></li>
<li>Bootstrap Confidence Intervals
<ul>
<li>Approximates sampling distribution</li>
<li>Bias correction</li>
<li>Acceleration</li>
<li>Flexibility for small samples</li>
</ul></li>
</ul>
</div>
<div id="simulation-studies" class="section level2 hasAnchor" number="14.5">
<h2><span class="header-section-number">E.5</span> Simulation Studies<a href="#simulation-studies" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Assessed accuracy and precision of MLE</li>
<li>Metrics:
<ul>
<li>Bias</li>
<li>Coverage probability</li>
<li>Confidence interval width</li>
</ul></li>
<li>Key scenarios:
<ul>
<li>Varying sample size</li>
<li>Censoring level</li>
<li>Masking probability</li>
<li>Component parameters</li>
</ul></li>
</ul>
</div>
<div id="conclusion-1" class="section level2 hasAnchor" number="14.6">
<h2><span class="header-section-number">E.6</span> Conclusion<a href="#conclusion-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>Provided likelihood framework for limited data</li>
<li>MLE accurate under small samples and masking</li>
<li>Bootstrap CIs well-calibrated</li>
<li>Shape parameters sensitive, scales more robust</li>
</ul>

<div id="refs" class="references hanging-indent">
<div id="ref-Abernethy2006">
<p>Abernethy, Robert B. 2006. <em>New Weibull Handbook</em>. 5th ed. Abernethy.</p>
</div>
<div id="ref-Agustin-2011">
<p>Agustin, Marcus. 2011. “Systems in Series.” In <em>Wiley Encyclopedia of Operations Research and Management Science</em>. John Wiley &amp; Sons, Ltd. <a href="https://doi.org/https://doi.org/10.1002/9780470400531.eorms0866">https://doi.org/https://doi.org/10.1002/9780470400531.eorms0866</a>.</p>
</div>
<div id="ref-bain1992">
<p>Bain, L. J., and M. Engelhardt. 1992. <em>Introduction to Probability and Mathematical Statistics</em>. Second. Duxbury Press.</p>
</div>
<div id="ref-casella2002statistical">
<p>Casella, George, and Roger L Berger. 2002. <em>Statistical Inference</em>. Duxbury Advanced Series.</p>
</div>
<div id="ref-cox1972regression">
<p>Cox, D. R. 1972. “Regression Models and Life-Tables.” <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 34 (2): 187–202. <a href="https://doi.org/https://doi.org/10.1111/j.2517-6161.1972.tb00899.x">https://doi.org/https://doi.org/10.1111/j.2517-6161.1972.tb00899.x</a>.</p>
</div>
<div id="ref-efron1987better">
<p>Efron, B. 1987. “Better Bootstrap Confidence Intervals.” <em>Journal of the American Statistical Association</em> 82 (397): 171–85.</p>
</div>
<div id="ref-efron1994introduction">
<p>Efron, Bradley, and Robert J Tibshirani. 1994. <em>An Introduction to the Bootstrap</em>. CRC press.</p>
</div>
<div id="ref-Fran-1991">
<p>Guess, Frank M., Thom J. Hodgson, and John S. Usher. 1991. “Estimating System and Component Reliabilities Under Partial Information on Cause of Failure.” <em>Journal of Statistical Planning and Inference</em> 29 (1-2): 75–85. <a href="https://doi.org/10.1016/0378-3758(92)90123-a">https://doi.org/10.1016/0378-3758(92)90123-a</a>.</p>
</div>
<div id="ref-Huairu-2013">
<p>Guo, Huairui, Pengying Niu, and F. Szidarovszky. 2013. “Estimating Component Reliabilities from Incomplete System Failure Data.” <em>Annual Reliability and Maintainability Symposium (RAMS)</em>, January, 1–6. <a href="https://doi.org/10.1109/rams.2013.6517765">https://doi.org/10.1109/rams.2013.6517765</a>.</p>
</div>
<div id="ref-klein2005survival">
<p>Klein, John P, and Melvin L Moeschberger. 2005. <em>Survival Analysis: Techniques for Censored and Truncated Data</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-lehmann1998theory">
<p>Lehmann, Erich L., and George Casella. 1998. <em>Theory of Point Estimation</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-taleb2007black">
<p>Taleb, Nassim Nicholas. 2007. <em>The Black Swan: The Impact of the Highly Improbable</em>. Random House.</p>
</div>
<div id="ref-wu1983convergence">
<p>Wu, C. F. Jeff. 1983. “On the Convergence Properties of the Em Algorithm.” <em>The Annals of Statistics</em> 11 (1): 95–103.</p>
</div>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><span class="math inline">\(T_i\)</span> is non-negative and continuous, <span class="math inline">\(R_{T_i}(t;\boldsymbol{\theta})\)</span> is a well-defined,
continuous, and differential function for <span class="math inline">\(t &gt; 0\)</span>, and <span class="math inline">\(\int_0^\infty R_{T_i}(t;\boldsymbol{\theta}) dt\)</span>
converges.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>A “fat-tailed” distribution refers to a probability distribution with tails that
decay more slowly than those of the exponential family, such as the case with the Weibull
when its shape parameter is greater than <span class="math inline">\(1\)</span>. This means that extreme values are more
likely to occur, and the distribution is more prone to “black swan” events or rare occurrences.
In the context of reliability, a fat-tailed distribution might imply a higher likelihood of
unusually long lifetimes, which can skew measures like the MTTF. <span class="citation">(Taleb <a href="#ref-taleb2007black" role="doc-biblioref">2007</a>)</span><a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>In some likelihood models, there may be more than two possible values for
<span class="math inline">\(\delta_i\)</span>, but in this paper, we only consider the case where <span class="math inline">\(\delta_i\)</span> is binary.
Future work could consider the case where <span class="math inline">\(\delta_i\)</span> is categorical by
including more types of censoring events and more types of component cause of
failure masking.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>The exponential distribution is a special case of the Weibull distribution when <span class="math inline">\(k_j = 1\)</span>.<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
